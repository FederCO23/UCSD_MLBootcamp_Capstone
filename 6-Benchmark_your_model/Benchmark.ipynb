{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a baseline model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective\n",
    "To define a baseline model, which is a simple and often minimalist machine learning model that serves as a starting point for solving a particular task. The baseline model will provide a reference point to evaluate the performance of more complex models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "\n",
    "To establish a benchmark for evaluating the performance of more complex models, I will implement three simple baseline models:\n",
    "\n",
    "* **Random Model**: This model randomly classifies each pixel into the positive or negative class based on the overall class distribution in the dataset. While simplistic, it serves as a lower bound for performance and helps ensure that more advanced models are better than chance.\n",
    "\n",
    "* **Threshold Classifier**: This model classifies pixels based on a fixed intensity threshold for the NIR band. Pixels with intensity values below the threshold are classified as positive, while those above are classified as negative.\n",
    "\n",
    "* **Logistic Regression Model**: A slightly more sophisticated approach, this model uses logistic regression to predict the class of each pixel based on its NIR intensity. By learning a probabilistic decision boundary, it provides a stronger base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import glob\n",
    "import random\n",
    "import imageio\n",
    "import imageio.v2 as imageio  # Explicitly use version 2 API\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from PIL import Image\n",
    "\n",
    "import re\n",
    "import rasterio\n",
    "from rasterio.enums import Resampling\n",
    "\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "CUDA available: True\n",
      "GPU Model: NVIDIA GeForce GTX 1080 Ti\n",
      "CUDA Version: 11.8\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Device Properties:\n",
      "  Name: NVIDIA GeForce GTX 1080 Ti\n",
      "  Total Memory (GB): 10.999755859375\n",
      "  Multiprocessors: 28\n",
      "  Compute Capability: 6 . 1\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(70*'-')\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "current_device = torch.cuda.current_device()\n",
    "print(\"GPU Model:\", torch.cuda.get_device_name(current_device))\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(70*'-')\n",
    "\n",
    "device_properties = torch.cuda.get_device_properties(current_device)\n",
    "print(\"\\nDevice Properties:\")\n",
    "print(\"  Name:\", device_properties.name)\n",
    "print(\"  Total Memory (GB):\", device_properties.total_memory / (1024 ** 3))  # Convert bytes to GB\n",
    "print(\"  Multiprocessors:\", device_properties.multi_processor_count)\n",
    "print(\"  Compute Capability:\", device_properties.major, \".\", device_properties.minor)\n",
    "print(70*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset\n",
    "- Import folder with images\n",
    "- Import folder with masks\n",
    "- Create list with training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the numeric value from filenames\n",
    "def numeric_sort_key(filepath):\n",
    "    # Extract numbers from the filename using a regular expression\n",
    "    match = re.search(r'\\d+', filepath)\n",
    "    # Return the integer value of the number if found, otherwise 0\n",
    "    return int(match.group()) if match else 0\n",
    "    \n",
    "# Get all the image and mask paths and sort them numerically\n",
    "folder_data_train = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2/train/input/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "folder_mask_train = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2/train/labels/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "\n",
    "folder_data_val = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2/val/input/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "folder_mask_val = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2/val/labels/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "\n",
    "folder_data_test = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2/test/input/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "folder_mask_test = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2/test/labels/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "\n",
    "# Assign to variables\n",
    "train_image_paths = folder_data_train[:]\n",
    "val_image_paths = folder_data_val[:]\n",
    "test_image_paths = folder_data_test[:]\n",
    "\n",
    "train_mask_paths = folder_mask_train[:]\n",
    "val_mask_paths = folder_mask_val[:]\n",
    "test_mask_paths = folder_mask_test[:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Control number of images by folder:\n",
      "========================================\n",
      "\t\tinput: \tlabels:\n",
      "Train\t\t201\t201\t73.90%\n",
      "Val\t\t35\t35\t12.87%\n",
      "Test\t\t36\t36\t13.24%\n",
      "========================================\n",
      "Total\t\t272\t272\n"
     ]
    }
   ],
   "source": [
    "# Check the number of train, val and test images\n",
    "print('\\nControl number of images by folder:')\n",
    "print(40*'=')\n",
    "input_total = len(folder_data_train)+len(folder_data_val)+len(folder_data_test)\n",
    "labels_total = len(folder_mask_train)+len(folder_mask_val)+len(folder_mask_test)\n",
    "print('\\t\\tinput: \\tlabels:')\n",
    "print(f'Train\\t\\t{len(folder_data_train)}\\t{len(folder_mask_train)}\\t{(len(folder_data_train)/input_total)*100:.2f}%')\n",
    "print(f'Val\\t\\t{len(folder_data_val)}\\t{len(folder_mask_val)}\\t{(len(folder_data_val)/input_total)*100:.2f}%')\n",
    "print(f'Test\\t\\t{len(folder_data_test)}\\t{len(folder_mask_test)}\\t{(len(folder_data_test)/input_total)*100:.2f}%')\n",
    "print(40*'=')\n",
    "print(f'Total\\t\\t{input_total}\\t{labels_total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(image_paths, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plot histograms for each band (R, G, B, NIR) for a given sample of images.\n",
    "    \"\"\"\n",
    "    red_values = []\n",
    "    green_values = []\n",
    "    blue_values = []\n",
    "    nir_values = []\n",
    "    \n",
    "    # Iterate over a subset of images\n",
    "    for img_path in image_paths[:num_samples]:  \n",
    "        image = imageio.imread(img_path)\n",
    "        \n",
    "        # Separate the bands\n",
    "        red_values.extend(image[:, :, 0].flatten())\n",
    "        green_values.extend(image[:, :, 1].flatten())\n",
    "        blue_values.extend(image[:, :, 2].flatten())\n",
    "        nir_values.extend(image[:, :, 3].flatten())\n",
    "\n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(red_values, bins=50, color='red', alpha=0.7)\n",
    "    plt.title(\"Red Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(green_values, bins=50, color='green', alpha=0.7)\n",
    "    plt.title(\"Green Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(blue_values, bins=50, color='blue', alpha=0.7)\n",
    "    plt.title(\"Blue Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(nir_values, bins=50, color='purple', alpha=0.7)\n",
    "    plt.title(\"NIR Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Call the function with your training image paths\n",
    "plot_histograms(train_image_paths, num_samples=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images statistics by band\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def central_stats(image_paths):\n",
    "    # Initialize arrays to accumulate mean, std, min and max values for each band\n",
    "    mean_values = np.zeros(4)\n",
    "    std_values = np.zeros(4)\n",
    "    min_values = np.full(4, np.inf)\n",
    "    max_values = np.full(4, -np.inf)\n",
    "    \n",
    "    n_pixels = 0  # Total pixel count across all images (for averaging)\n",
    "    \n",
    "    # Iterate over all images in the training set\n",
    "    for img_path in image_paths:\n",
    "        # Load the image and cast to float32 for precision\n",
    "        image = imageio.imread(img_path).astype(np.float32)\n",
    "        \n",
    "        # Calculate the mean and std per band for this image\n",
    "        mean_per_image = image.mean(axis=(0, 1))  # Mean across spatial dimensions\n",
    "        std_per_image = image.std(axis=(0, 1))    # Std deviation across spatial dimensions\n",
    "        \n",
    "        # Accumulate the total mean and std values\n",
    "        mean_values += mean_per_image\n",
    "        std_values += std_per_image\n",
    "            \n",
    "        # Calculate and update the min and max per band\n",
    "        min_per_image = image.min(axis=(0, 1))\n",
    "        max_per_image = image.max(axis=(0, 1))\n",
    "        for i in range(len(min_values)):\n",
    "            min_values[i] = min(min_values[i], min_per_image[i])\n",
    "            max_values[i] = max(max_values[i], max_per_image[i])\n",
    "    \n",
    "    # Average the mean and std across all images\n",
    "    mean_values /= len(image_paths)\n",
    "    std_values /= len(image_paths)\n",
    "    \n",
    "    print(\"Mean per band (R, G, B, NIR):\", mean_values)\n",
    "    print(\"Std deviation per band (R, G, B, NIR):\", std_values)\n",
    "    print(\"Min values per band (R, G, B, NIR):\", min_values)\n",
    "    print(\"Max values per band (R, G, B, NIR):\", max_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per band (R, G, B, NIR): [ 927.75739512  740.14410416  492.39665161 2441.67961341]\n",
      "Std deviation per band (R, G, B, NIR): [420.10468167 257.58737858 200.92512581 500.59008288]\n",
      "Min values per band (R, G, B, NIR): [ 38.  74.  35. 123.]\n",
      "Max values per band (R, G, B, NIR): [9380. 9224. 8710. 8791.]\n"
     ]
    }
   ],
   "source": [
    "central_stats(train_image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1- Random Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomModel(nn.Module):\n",
    "    def __init__(self, positive_prob):\n",
    "        \"\"\"\n",
    "        Random model that generates predictions based on the distribution of positive and negative classes.\n",
    "        \"\"\"\n",
    "        super(RandomModel, self).__init__()\n",
    "        self.positive_prob = positive_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the random model.\n",
    "        It generates random predictions based on the class distribution.\n",
    "        \"\"\"\n",
    "        batch_size, _, height, width = x.size()\n",
    "        random_probs = torch.rand(batch_size, 1, height, width, device=x.device)\n",
    "        random_preds = (random_probs < self.positive_prob).float()\n",
    "        return random_preds\n",
    "\n",
    "def compute_positive_class_probability(mask_paths):\n",
    "    \"\"\"\n",
    "    Compute the probability of the positive class (1) across all training masks.\n",
    "    \"\"\"\n",
    "    total_pixels = 0\n",
    "    positive_pixels = 0\n",
    "\n",
    "    for mask_path in mask_paths:\n",
    "        mask = imageio.imread(mask_path)\n",
    "        total_pixels += mask.size\n",
    "        positive_pixels += np.sum(mask)  # Assuming positive class is represented by 1\n",
    "\n",
    "    positive_prob = positive_pixels / total_pixels\n",
    "    return positive_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Class Probability: 0.0230\n"
     ]
    }
   ],
   "source": [
    "positive_prob = compute_positive_class_probability(train_mask_paths)\n",
    "print(f\"Positive Class Probability: {positive_prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_confusion_matrix_with_distributions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[237], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m random_model \u001b[38;5;241m=\u001b[39m RandomModel(positive_prob\u001b[38;5;241m=\u001b[39mpositive_prob)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m cm, pos_probs, neg_probs, nb_of_images_eval \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_confusion_matrix_with_distributions\u001b[49m(random_model, test_loader, DEVICE)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Model Results (with class distribution):\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     10\u001b[0m display_confusion_matrix_with_metrics_and_distributions(cm, pos_probs, neg_probs, nb_of_images_eval)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_confusion_matrix_with_distributions' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute the positive class probability from the training masks\n",
    "positive_prob = compute_positive_class_probability(train_mask_paths)\n",
    "\n",
    "# Initialize the random model\n",
    "random_model = RandomModel(positive_prob=positive_prob).to(DEVICE)\n",
    "\n",
    "# Evaluate the model\n",
    "cm, pos_probs, neg_probs, nb_of_images_eval = compute_confusion_matrix_with_distributions(random_model, test_loader, DEVICE)\n",
    "print(\"Random Model Results (with class distribution):\")\n",
    "display_confusion_matrix_with_metrics_and_distributions(cm, pos_probs, neg_probs, nb_of_images_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_NIR_hist_per_class(image_paths, mask_paths, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plot histograms for NIR band according with mask's binary classification (1- possitive and 0- background)\n",
    "    \"\"\"\n",
    "    nir_values_positive = []\n",
    "    nir_values_negative = []\n",
    "    result = []\n",
    "\n",
    "    for img_path, mask_path in zip(image_paths[:num_samples], mask_paths[:num_samples]):\n",
    "        image = imageio.imread(img_path)\n",
    "        mask = imageio.imread(mask_path)\n",
    "\n",
    "        # define the two arrays\n",
    "        nir_values = image[:, :, 3].flatten()\n",
    "        mask_values = mask[:,:].flatten()\n",
    "\n",
    "        # multiply element-wise the image array with the mask array. \n",
    "        # Then, the result are the reflectance pixel value for the NIR band where the mask is positive (1)\n",
    "        nir_values_positive.extend(nir_values * mask_values)\n",
    "        nir_values_negative.extend(nir_values * (1 - mask_values))\n",
    "\n",
    "    # drop the zero values\n",
    "    # (consider that the minimum values for the NIR band images across the entire dataset are greater than zero)\n",
    "    nir_values_positive = np.array([nir_values_positive])\n",
    "    nir_values_negative = np.array([nir_values_negative])\n",
    "    positives_nonzero = nir_values_positive[nir_values_positive != 0 ]\n",
    "    negatives_nonzero = nir_values_negative[nir_values_negative != 0 ]\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    plt.hist(positives_nonzero, bins=200, color='red', alpha=0.7, label=\"Positive class NIR pixels distribution\")\n",
    "    plt.hist(negatives_nonzero, bins=200, color='grey', alpha=0.7, label=\"Negative class NIR pixels distribution\")\n",
    "    plt.title(\"NIR Band Pixel Distribution for Positive and Negative Mask Classes\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    nb_pixels = positives_nonzero.shape[0] + negatives_nonzero.shape[0]\n",
    "    nb_images = nb_pixels / (image.shape[0] * image.shape[1])\n",
    "    return print(f\"{nb_pixels:,} pixels considered from {int(nb_images)} images \")    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13,172,736 pixels considered from 201 images \n"
     ]
    }
   ],
   "source": [
    "plot_NIR_hist_per_class(train_image_paths, train_mask_paths, num_samples=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201.0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "13172736/(256*256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------\n",
      "CUDA available: True\n",
      "GPU Model: NVIDIA GeForce GTX 1080 Ti\n",
      "CUDA Version: 11.8\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Device Properties:\n",
      "  Name: NVIDIA GeForce GTX 1080 Ti\n",
      "  Total Memory (GB): 10.999755859375\n",
      "  Multiprocessors: 28\n",
      "  Compute Capability: 6 . 1\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(70*'-')\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "current_device = torch.cuda.current_device()\n",
    "print(\"GPU Model:\", torch.cuda.get_device_name(current_device))\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(70*'-')\n",
    "\n",
    "device_properties = torch.cuda.get_device_properties(current_device)\n",
    "print(\"\\nDevice Properties:\")\n",
    "print(\"  Name:\", device_properties.name)\n",
    "print(\"  Total Memory (GB):\", device_properties.total_memory / (1024 ** 3))  # Convert bytes to GB\n",
    "print(\"  Multiprocessors:\", device_properties.multi_processor_count)\n",
    "print(\"  Compute Capability:\", device_properties.major, \".\", device_properties.minor)\n",
    "print(70*'-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before importing the dataset, apply Super Resolution to the source images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the numeric value from filenames\n",
    "def numeric_sort_key(filepath):\n",
    "    # Extract numbers from the filename using a regular expression\n",
    "    match = re.search(r'\\d+', filepath)\n",
    "    # Return the integer value of the number if found, otherwise 0\n",
    "    return int(match.group()) if match else 0\n",
    "    \n",
    "def preprocess_dataset(image_dir, mask_dir, output_dir, scale_factor=2):\n",
    "    \"\"\"\n",
    "    Preprocess the dataset by applying super-resolution and saving the results using rasterio.\n",
    "    \n",
    "    Args:\n",
    "        image_dir (str): Directory containing input images.\n",
    "        mask_dir (str): Directory containing mask images.\n",
    "        output_dir (str): Base directory to store the preprocessed data.\n",
    "        scale_factor (int): Factor by which to upscale the images.\n",
    "    \"\"\"\n",
    "    # Get all the image and mask paths and sort them numerically\n",
    "    image_paths = sorted(glob.glob(f\"{image_dir}/*.tif\"), key=numeric_sort_key)\n",
    "    mask_paths = sorted(glob.glob(f\"{mask_dir}/*.tif\"), key=numeric_sort_key)\n",
    "\n",
    "    # Create output directories for images and masks\n",
    "    images_output_dir = Path(output_dir) / \"input\"\n",
    "    masks_output_dir = Path(output_dir) / \"labels\"\n",
    "    images_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    masks_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Process images\n",
    "    print(f\"Processing {len(image_paths)} images...\")\n",
    "    for img_path in image_paths:\n",
    "        with rasterio.open(img_path) as src:\n",
    "            # Read and upscale each band\n",
    "            upscaled_data = []\n",
    "            for band in range(1, src.count + 1):  # Loop through bands\n",
    "                band_data = src.read(band)\n",
    "                upscaled_band = zoom(band_data, scale_factor, order=3)  # Cubic interpolation\n",
    "                upscaled_data.append(upscaled_band)\n",
    "            \n",
    "            # Write to a new file\n",
    "            meta = src.meta.copy()\n",
    "            meta.update({\n",
    "                \"height\": int(src.height * scale_factor),\n",
    "                \"width\": int(src.width * scale_factor),\n",
    "                \"transform\": src.transform * rasterio.Affine.scale(1 / scale_factor),\n",
    "            })\n",
    "            output_path = images_output_dir / os.path.basename(img_path)\n",
    "            with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "                for i, band_data in enumerate(upscaled_data, start=1):\n",
    "                    dst.write(band_data, i)\n",
    "    \n",
    "    # Process masks\n",
    "    print(f\"Processing {len(mask_paths)} masks...\")\n",
    "    for mask_path in mask_paths:\n",
    "        with rasterio.open(mask_path) as src:\n",
    "            mask_data = src.read(1)  # Single-band mask\n",
    "            upscaled_mask = zoom(mask_data, scale_factor, order=0)  # Nearest-neighbor interpolation\n",
    "            \n",
    "            # Write to a new file\n",
    "            meta = src.meta.copy()\n",
    "            meta.update({\n",
    "                \"height\": int(src.height * scale_factor),\n",
    "                \"width\": int(src.width * scale_factor),\n",
    "                \"transform\": src.transform * rasterio.Affine.scale(1 / scale_factor),\n",
    "            })\n",
    "            output_path = masks_output_dir / os.path.basename(mask_path)\n",
    "            with rasterio.open(output_path, \"w\", **meta) as dst:\n",
    "                dst.write(upscaled_mask, 1)\n",
    "\n",
    "    print(f\"Preprocessing complete. Data saved to: {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_dataset(\n",
    "#     image_dir = '../5-Data_Wrangling/data_split2/train/input/', \n",
    "#     mask_dir = '../5-Data_Wrangling/data_split2/train/labels/',\n",
    "#     output_dir = '../5-Data_Wrangling/data_split2sr/train/',\n",
    "#     scale_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_dataset(\n",
    "#     image_dir = '../5-Data_Wrangling/data_split2/val/input/', \n",
    "#     mask_dir = '../5-Data_Wrangling/data_split2/val/labels/',\n",
    "#     output_dir = '../5-Data_Wrangling/data_split2sr/val/',\n",
    "#     scale_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess_dataset(\n",
    "#     image_dir = '../5-Data_Wrangling/data_split2/test/input/', \n",
    "#     mask_dir = '../5-Data_Wrangling/data_split2/test/labels/',\n",
    "#     output_dir = '../5-Data_Wrangling/data_split2sr/test/',\n",
    "#     scale_factor=2\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataset\n",
    "- Import folder with images\n",
    "- Import folder with masks\n",
    "- Create list with training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all the image and mask paths and sort them numerically\n",
    "folder_data_train = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2sr/train/input/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "folder_mask_train = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2sr/train/labels/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "\n",
    "folder_data_val = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2sr/val/input/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "folder_mask_val = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2sr/val/labels/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "\n",
    "folder_data_test = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2sr/test/input/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "folder_mask_test = sorted(\n",
    "    glob.glob(\"../5-Data_Wrangling/data_split2sr/test/labels/*tif\"),\n",
    "    key=numeric_sort_key\n",
    ")\n",
    "\n",
    "# # Assign to variables\n",
    "# train_image_paths = folder_data_train[:]\n",
    "# val_image_paths = folder_data_val[:]\n",
    "# test_image_paths = folder_data_test[:]\n",
    "\n",
    "# train_mask_paths = folder_mask_train[:]\n",
    "# val_mask_paths = folder_mask_val[:]\n",
    "# test_mask_paths = folder_mask_test[:]\n",
    "\n",
    "# debugging\n",
    "train_image_paths = folder_data_train[:100]\n",
    "val_image_paths = folder_data_val[:12]\n",
    "test_image_paths = folder_data_test[:12]\n",
    "\n",
    "train_mask_paths = folder_mask_train[:100]\n",
    "val_mask_paths = folder_mask_val[:12]\n",
    "test_mask_paths = folder_mask_test[:12]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Control number of images by folder:\n",
      "========================================\n",
      "\t\tinput: \tlabels:\n",
      "Train\t\t201\t201\t73.90%\n",
      "Val\t\t35\t35\t12.87%\n",
      "Test\t\t36\t36\t13.24%\n",
      "========================================\n",
      "Total\t\t272\t272\n"
     ]
    }
   ],
   "source": [
    "# Check the number of train, val and test images\n",
    "print('\\nControl number of images by folder:')\n",
    "print(40*'=')\n",
    "input_total = len(folder_data_train)+len(folder_data_val)+len(folder_data_test)\n",
    "labels_total = len(folder_mask_train)+len(folder_mask_val)+len(folder_mask_test)\n",
    "print('\\t\\tinput: \\tlabels:')\n",
    "print(f'Train\\t\\t{len(folder_data_train)}\\t{len(folder_mask_train)}\\t{(len(folder_data_train)/input_total)*100:.2f}%')\n",
    "print(f'Val\\t\\t{len(folder_data_val)}\\t{len(folder_mask_val)}\\t{(len(folder_data_val)/input_total)*100:.2f}%')\n",
    "print(f'Test\\t\\t{len(folder_data_test)}\\t{len(folder_mask_test)}\\t{(len(folder_data_test)/input_total)*100:.2f}%')\n",
    "print(40*'=')\n",
    "print(f'Total\\t\\t{input_total}\\t{labels_total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histograms(image_paths, num_samples=5):\n",
    "    \"\"\"\n",
    "    Plot histograms for each band (R, G, B, NIR) for a given sample of images.\n",
    "    \"\"\"\n",
    "    red_values = []\n",
    "    green_values = []\n",
    "    blue_values = []\n",
    "    nir_values = []\n",
    "    \n",
    "    # Iterate over a subset of images\n",
    "    for img_path in image_paths[:num_samples]:  \n",
    "        image = imageio.imread(img_path)\n",
    "        \n",
    "        # Separate the bands\n",
    "        red_values.extend(image[:, :, 0].flatten())\n",
    "        green_values.extend(image[:, :, 1].flatten())\n",
    "        blue_values.extend(image[:, :, 2].flatten())\n",
    "        nir_values.extend(image[:, :, 3].flatten())\n",
    "    \n",
    "    # Plot histograms\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    \n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.hist(red_values, bins=50, color='red', alpha=0.7)\n",
    "    plt.title(\"Red Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.hist(green_values, bins=50, color='green', alpha=0.7)\n",
    "    plt.title(\"Green Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.hist(blue_values, bins=50, color='blue', alpha=0.7)\n",
    "    plt.title(\"Blue Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.hist(nir_values, bins=50, color='purple', alpha=0.7)\n",
    "    plt.title(\"NIR Band Histogram\")\n",
    "    plt.xlabel(\"Pixel Intensity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function with your training image paths\n",
    "#plot_histograms(train_image_paths, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_balance_from_paths(mask_paths):\n",
    "    \"\"\"\n",
    "    Calculate the class balance (proportion of positive and negative pixels) for a dataset using mask file paths.\n",
    "    Args:\n",
    "        mask_paths: List of file paths to mask images.\n",
    "    Returns:\n",
    "        class_balance: Dictionary with the proportion of positive and negative pixels.\n",
    "    \"\"\"\n",
    "    total_pixels = 0\n",
    "    positive_pixels = 0\n",
    "\n",
    "    for mask_path in mask_paths:\n",
    "        mask = imageio.imread(mask_path).astype(np.float32)\n",
    "        mask = np.where(mask > 0.5, 1, 0)\n",
    "        \n",
    "        total_pixels += mask.size\n",
    "        positive_pixels += mask.sum()\n",
    "\n",
    "    negative_pixels = total_pixels - positive_pixels\n",
    "\n",
    "    # Calculate proportions\n",
    "    positive_ratio = positive_pixels / total_pixels\n",
    "    negative_ratio = negative_pixels / total_pixels\n",
    "\n",
    "    class_balance = {\n",
    "        \"positive_ratio\": positive_ratio,\n",
    "        \"negative_ratio\": negative_ratio,\n",
    "        \"total_pixels\": total_pixels,\n",
    "    }\n",
    "\n",
    "    return class_balance\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Balance in Training Set: {'positive_ratio': 0.041524200439453124, 'negative_ratio': 0.9584757995605468, 'total_pixels': 26214400}\n",
      "Class Balance in Validation Set: {'positive_ratio': 0.045077006022135414, 'negative_ratio': 0.9549229939778646, 'total_pixels': 3145728}\n",
      "Class Balance in Test Set: {'positive_ratio': 0.1297022501627604, 'negative_ratio': 0.8702977498372396, 'total_pixels': 3145728}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the training, validation, and test sets class balance\n",
    "train_balance = calculate_class_balance_from_paths(train_mask_paths)\n",
    "val_balance = calculate_class_balance_from_paths(val_mask_paths)\n",
    "test_balance = calculate_class_balance_from_paths(test_mask_paths)\n",
    "\n",
    "print(\"Class Balance in Training Set:\", train_balance)\n",
    "print(\"Class Balance in Validation Set:\", val_balance)\n",
    "print(\"Class Balance in Test Set:\", test_balance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization: Calculate Mean and StdDev from the training set (consider the 4-bands)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean per band (R, G, B, NIR): [ 927.72309094  740.12511994  492.37997292 2441.66539495]\n",
      "Std deviation per band (R, G, B, NIR): [419.47567552 257.08428302 200.48893916 499.48728449]\n"
     ]
    }
   ],
   "source": [
    "# For Image's normalization: Calculate Mean and Standard Deviation for all the training set\n",
    "\n",
    "train_image_paths = glob.glob(\"../5-Data_Wrangling/data_split2sr/train/input/*.tif\")\n",
    "\n",
    "# Initialize arrays to accumulate mean and std values for each band\n",
    "mean_values = np.zeros(4)\n",
    "std_values = np.zeros(4)\n",
    "n_pixels = 0  # Total pixel count across all images (for averaging)\n",
    "\n",
    "# Iterate over all images in the training set\n",
    "for img_path in train_image_paths:\n",
    "    # Load the image and cast to float32 for precision\n",
    "    image = imageio.imread(img_path).astype(np.float32)\n",
    "    \n",
    "    # Calculate the mean and std per band for this image\n",
    "    mean_per_image = image.mean(axis=(0, 1))  # Mean across spatial dimensions\n",
    "    std_per_image = image.std(axis=(0, 1))    # Std deviation across spatial dimensions\n",
    "    \n",
    "    # Accumulate the total mean and std values\n",
    "    mean_values += mean_per_image\n",
    "    std_values += std_per_image\n",
    "    n_pixels += image.shape[0] * image.shape[1]  # Accumulate pixel count for averaging\n",
    "\n",
    "# Average the mean and std across all images\n",
    "mean_values /= len(train_image_paths)\n",
    "std_values /= len(train_image_paths)\n",
    "\n",
    "print(\"Mean per band (R, G, B, NIR):\", mean_values)\n",
    "print(\"Std deviation per band (R, G, B, NIR):\", std_values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Resolution using CV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_super_resolution_opencv(image, scale_factor=2, interpolation=cv2.INTER_CUBIC):\n",
    "#     \"\"\"\n",
    "#     Apply OpenCV interpolation to enhance image resolution.\n",
    "#     Args:\n",
    "#         image (numpy array): Input image as a numpy array.\n",
    "#         scale_factor (int): Factor by which to upscale the image.\n",
    "#         interpolation: Interpolation method (default is cv2.INTER_CUBIC).\n",
    "#     Returns:\n",
    "#         numpy array: Upscaled image.\n",
    "#     \"\"\"\n",
    "#     height, width = image.shape[:2]\n",
    "#     new_dimensions = (width * scale_factor, height * scale_factor)\n",
    "#     upscaled_image = cv2.resize(image, new_dimensions, interpolation=interpolation)\n",
    "#     return upscaled_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, image_paths, target_paths, transform=None, band=None, device='cuda'):\n",
    "\n",
    "        self.image_paths = image_paths\n",
    "        self.target_paths = target_paths\n",
    "        self.transform = transform\n",
    "        self.band = band # Specify which band to use (0: R, 1: G, 2: B, 3: NIR, None: all bands)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.device = device  # Specify the device for preloading\n",
    "\n",
    "        # Preload images and masks into GPU memory\n",
    "        print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Preloading images and masks into GPU memory...\")\n",
    "        # self.images = [torch.tensor(cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32), device=self.device) for path in image_paths]\n",
    "        # self.masks = [torch.tensor(cv2.imread(path, cv2.IMREAD_UNCHANGED).astype(np.float32), device=self.device) for path in target_paths]\n",
    "        self.images = image_paths\n",
    "        self.masks = target_paths\n",
    "        print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Preloading complete.\")\n",
    "\n",
    "        \n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        # Debugging: Print dataset lengths and current index\n",
    "        print(f\"[DEBUG] Dataset size: {len(self.image_paths)} images, {len(self.masks)} masks\")\n",
    "        print(f\"[DEBUG] Current index: {index}\")\n",
    "    \n",
    "        # Access the paths safely\n",
    "        try:\n",
    "            # Get the current timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            \n",
    "             # Log the index being loaded\n",
    "            print(f\"[{timestamp}] Loading image and mask for index {index}...\")\n",
    "            \n",
    "            # Retrieve preloaded image and mask\n",
    "            # image = self.images[index]\n",
    "            # mask = self.masks[index]\n",
    "             # Debugging: Add print statements for image and mask paths\n",
    "            print(f\"Loading image: {self.image_paths[index]}\")\n",
    "            print(f\"Loading mask: {self.masks[index]}\")\n",
    "            image = torch.tensor(cv2.imread(self.images[index], cv2.IMREAD_UNCHANGED).astype(np.float32))\n",
    "            mask = torch.tensor(cv2.imread(self.masks[index], cv2.IMREAD_UNCHANGED).astype(np.float32))\n",
    "            print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "            print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}\")\n",
    "               \n",
    "            # Select a specific band if specified\n",
    "            if self.band is not None:\n",
    "                image = image[:, :, self.band].unsqueeze(2)  # Add channel dimension\n",
    "\n",
    "                \n",
    "            # Normalize the image\n",
    "            # image_reshaped = image.reshape(-1, image.shape[-1])\n",
    "            # image_scaled = self.scaler.fit_transform(image_reshaped)\n",
    "            # image = image_scaled.reshape(image.shape)\n",
    "\n",
    "             # Normalize the image (Min-Max normalization)\n",
    "            image_min = image.min()\n",
    "            image_max = image.max()\n",
    "            if image_max > image_min:  # Avoid division by zero\n",
    "                image = (image - image_min) / (image_max - image_min)\n",
    "\n",
    "            # Reshape for MinMaxScaler and apply normalization\n",
    "            #image_reshaped = image.reshape(-1, 4)\n",
    "            #image_scaled = self.scaler.fit_transform(image_reshaped)\n",
    "            #image = image_scaled.reshape(image.shape)\n",
    "            \n",
    "            # Load the 1-band binary mask\n",
    "            # mask = imageio.imread(self.target_paths[index])\n",
    "            # mask = np.asarray(mask, dtype='float32')\n",
    "            #mask = np.where(mask>1, 0, mask) # some images has soil annotations as well\n",
    "            mask = torch.where(mask > 1, torch.tensor(0.0, device=self.device), mask)\n",
    "    \n",
    "            # Debugging: Print shapes and types\n",
    "            #print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "            #print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}\")\n",
    "\n",
    "            # Debugging: Log the properties of the loaded image and mask\n",
    "            print(f\"[{timestamp}] Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "            print(f\"[{timestamp}] Mask shape: {mask.shape}, dtype: {mask.dtype}\")\n",
    "\n",
    "    \n",
    "            # Apply the transformation to both image and mask if self.transform is set\n",
    "            if self.transform:\n",
    "                try:\n",
    "                    image, mask = self.transform(image, mask)  # Pass both to transform if synchronized\n",
    "                except Exception as e:\n",
    "                    print(f\"[{timestamp}] Error during transformation at index {index}: {e}\")\n",
    "                    raise e\n",
    "    \n",
    "            return image, mask\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] Error at index {index}: {e}\")\n",
    "            raise e\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        return len(self.image_paths)\n",
    "\n",
    "\n",
    "\n",
    "# class CustomDataset(data.Dataset):\n",
    "#     def __init__(self, image_paths, target_paths, transform=None, band=None, apply_super_resolution=False, scale_factor=2):\n",
    "\n",
    "#         self.image_paths = image_paths\n",
    "#         self.target_paths = target_paths\n",
    "#         self.transform = transform\n",
    "#         self.band = band # Specify which band to use (0: R, 1: G, 2: B, 3: NIR, None: all bands)\n",
    "#         self.scaler = MinMaxScaler()\n",
    "#         self.apply_super_resolution = apply_super_resolution\n",
    "#         self.scale_factor = scale_factor  # Scaling factor for super-resolution\n",
    "#         #self.sr_model = sr_model\n",
    "#         #self.res_printed = False\n",
    "                \n",
    "#     def __getitem__(self, index):\n",
    "        \n",
    "#         image = imageio.imread(self.image_paths[index]).astype(np.float32)\n",
    "\n",
    "#         # Select a specific band if specified\n",
    "#         if self.band is not None:\n",
    "#             image = image[:, :, self.band] #Select only the specified band\n",
    "#             image = image[:, :, np.newaxis]\n",
    "            \n",
    "#         # Load the 1-band binary mask\n",
    "#         mask = imageio.imread(self.target_paths[index])\n",
    "#         mask = np.asarray(mask, dtype='float32')\n",
    "#         mask = np.where(mask>1, 0, mask) # some images has soil annotations as well\n",
    "\n",
    "#         # Apply super-resolution if enabled\n",
    "#         if self.apply_super_resolution:\n",
    "#             image = apply_super_resolution_opencv(image, scale_factor=self.scale_factor, interpolation=cv2.INTER_CUBIC)\n",
    "#             mask = apply_super_resolution_opencv(mask, scale_factor=self.scale_factor, interpolation=cv2.INTER_NEAREST)  # Use INTER_NEAREST for masks\n",
    "    \n",
    "#         # Normalize the image\n",
    "#         image_reshaped = image.reshape(-1, image.shape[-1])\n",
    "#         image_scaled = self.scaler.fit_transform(image_reshaped)\n",
    "#         image = image_scaled.reshape(image.shape)\n",
    "\n",
    "#         # # Convert to PyTorch tensor\n",
    "#         # image_tensor = torch.tensor(image).permute(2, 0, 1).unsqueeze(0).to(DEVICE)  # Add batch dimension\n",
    "\n",
    "#         # # Apply super-resolution if enabled\n",
    "#         # if self.apply_super_resolution and self.sr_model:\n",
    "#         #     with torch.no_grad():\n",
    "#         #         image_tensor = self.sr_model(image_tensor).squeeze(0)  # Remove batch dimension\n",
    "#         #         if not self.res_printed:\n",
    "#         #             print(f'image resolution after super res: {image_tensor.shape}')\n",
    "#         #             self.res_printed = True\n",
    "                            \n",
    "        \n",
    "#         # Debugging: Print shapes and types\n",
    "#         #print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "#         #print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}\")\n",
    "\n",
    "#         # Apply the transformation to both image and mask if self.transform is set\n",
    "#         if self.transform:\n",
    "#             image, mask = self.transform(image, mask)  # Pass both to transform if synchronized\n",
    "\n",
    "#         return image, mask\n",
    "\n",
    "\n",
    "#     def __len__(self):\n",
    "\n",
    "#         return len(self.image_paths)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynchronizedTransform:\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, image, mask):\n",
    "        # Convert tensors to NumPy arrays if needed\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            image = image.cpu().numpy()  # Move tensor to CPU and convert to NumPy array\n",
    "        if isinstance(mask, torch.Tensor):\n",
    "            mask = mask.cpu().numpy()  # Move tensor to CPU and convert to NumPy array\n",
    "        \n",
    "        # Convert numpy arrays to PIL images\n",
    "        if image.ndim == 3 and image.shape[-1] == 1:  # Single-band images\n",
    "            image = image.squeeze(-1)  # Remove the singleton channel\n",
    "        image = Image.fromarray((image * 255).astype(np.uint8))  # Scale to 0-255\n",
    "        mask = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "\n",
    "        for transform in self.transforms:\n",
    "            if isinstance(transform, transforms.RandomHorizontalFlip):\n",
    "                if torch.rand(1).item() < 0.5:\n",
    "                    image = TF.hflip(image)\n",
    "                    mask = TF.hflip(mask)\n",
    "            elif isinstance(transform, transforms.RandomVerticalFlip):\n",
    "                if torch.rand(1).item() < 0.5:\n",
    "                    image = TF.vflip(image)\n",
    "                    mask = TF.vflip(mask)\n",
    "            elif isinstance(transform, transforms.RandomChoice):\n",
    "                angle = random.choice([0, 90, 180, 270])\n",
    "                image = TF.rotate(image, angle)\n",
    "                mask = TF.rotate(mask, angle)\n",
    "            elif isinstance(transform, transforms.ToTensor):\n",
    "                image = TF.to_tensor(image)\n",
    "                mask = TF.to_tensor(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "# class SynchronizedTransform:\n",
    "#     def __init__(self, transforms):\n",
    "#         self.transforms = transforms\n",
    "\n",
    "#     def __call__(self, image, mask):\n",
    "#         # Convert tensors to NumPy arrays if needed\n",
    "#         if isinstance(image, torch.Tensor):\n",
    "#             image = image.numpy()  # Convert tensor to NumPy array\n",
    "#         if isinstance(mask, torch.Tensor):\n",
    "#             mask = mask.numpy()  # Convert tensor to NumPy array\n",
    "        \n",
    "        \n",
    "#         # Convert numpy arrays to PIL images\n",
    "#         #image = Image.fromarray((image * 255).astype(np.uint8))  # Scale to 0-255 for display\n",
    "\n",
    "#         # Convert numpy arrays to PIL images\n",
    "#         if image.ndim == 3 and image.shape[-1] == 1:  # Single-band images\n",
    "#             image = image.squeeze(-1)  # Remove the singleton channel\n",
    "\n",
    "#         # Conver to PIL images\n",
    "#         image = Image.fromarray((image * 255).astype(np.uint8))  # Scale to 0-255\n",
    "#         mask = Image.fromarray((mask * 255).astype(np.uint8))\n",
    "\n",
    "        \n",
    "#         for transform in self.transforms:\n",
    "#             if isinstance(transform, transforms.RandomHorizontalFlip):\n",
    "#                 if torch.rand(1).item() < 0.5:\n",
    "#                     image = TF.hflip(image)\n",
    "#                     mask = TF.hflip(mask)\n",
    "#             elif isinstance(transform, transforms.RandomVerticalFlip):\n",
    "#                 if torch.rand(1).item() < 0.5:\n",
    "#                     image = TF.vflip(image)\n",
    "#                     mask = TF.vflip(mask)\n",
    "#             elif isinstance(transform, transforms.RandomChoice):\n",
    "#                 # Pick a random rotation angle from the specified options\n",
    "#                 angle = random.choice([0, 90, 180, 270])\n",
    "#                 image = TF.rotate(image, angle)\n",
    "#                 mask = TF.rotate(mask, angle)\n",
    "#             elif isinstance(transform, transforms.ToTensor):\n",
    "#                 image = TF.to_tensor(image)\n",
    "#                 mask = TF.to_tensor(mask)\n",
    "\n",
    "#         return image, mask\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-08 15:00:46] Preloading images and masks into GPU memory...\n",
      "[2024-12-08 15:00:46] Preloading complete.\n",
      "[2024-12-08 15:00:46] Preloading images and masks into GPU memory...\n",
      "[2024-12-08 15:00:46] Preloading complete.\n",
      "[2024-12-08 15:00:46] Preloading images and masks into GPU memory...\n",
      "[2024-12-08 15:00:46] Preloading complete.\n"
     ]
    }
   ],
   "source": [
    "simple_transform = SynchronizedTransform([\n",
    "    transforms.ToTensor()  # Convert both image and mask to tensor\n",
    "])\n",
    "\n",
    "# augmentation_transform = SynchronizedTransform([\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.RandomVerticalFlip(),\n",
    "#     transforms.RandomChoice([\n",
    "#         transforms.RandomRotation(0),\n",
    "#         transforms.RandomRotation(90),\n",
    "#         transforms.RandomRotation(180),\n",
    "#         transforms.RandomRotation(270)\n",
    "#     ]),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "\n",
    "augmentation_transform = SynchronizedTransform([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomChoice([\n",
    "    #     transforms.RandomRotation(0),\n",
    "    #     transforms.RandomRotation(90),\n",
    "    #     transforms.RandomRotation(180),\n",
    "    #     transforms.RandomRotation(270)\n",
    "    # ]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Load a pre-trained super-resolution model (e.g., SRResNet)\n",
    "# sr_model = super_resolution.srresnet_1x().to(DEVICE)\n",
    "# sr_model.eval()\n",
    "\n",
    "use_all_bands = False\n",
    "model_band = 3 # 0:red, 1:green, 2:blue, 3:NIR, None:all 4 bands\n",
    "\n",
    "train_dataset = CustomDataset(train_image_paths, train_mask_paths, transform=augmentation_transform, band=model_band)\n",
    "val_dataset = CustomDataset(val_image_paths, val_mask_paths, transform=simple_transform, band=model_band)\n",
    "test_dataset = CustomDataset(test_image_paths, test_mask_paths, transform=simple_transform, band=model_band)\n",
    "\n",
    "# train_dataset = CustomDataset(train_image_paths, train_mask_paths, transform=augmentation_transform, band=model_band)\n",
    "# val_dataset = CustomDataset(val_image_paths, val_mask_paths, transform=simple_transform, band=model_band)\n",
    "# test_dataset = CustomDataset(test_image_paths, test_mask_paths, transform=simple_transform, band=model_band)\n",
    "\n",
    "# image, mask = train_dataset[0]  # Load the first item\n",
    "# print(f\"Transformed image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "# print(f\"Transformed mask shape: {mask.shape}, dtype: {mask.dtype}\")\n",
    "\n",
    "# train_dataset = CustomDataset(\n",
    "#     train_image_paths, \n",
    "#     train_mask_paths, \n",
    "#     transform=augmentation_transform, \n",
    "#     band=model_band, \n",
    "#     apply_super_resolution = True,\n",
    "#     scale_factor = 2)\n",
    "\n",
    "# val_dataset = CustomDataset(\n",
    "#     val_image_paths, \n",
    "#     val_mask_paths, \n",
    "#     transform=simple_transform, \n",
    "#     band=model_band, \n",
    "#     apply_super_resolution = True,\n",
    "#     scale_factor = 2)\n",
    "\n",
    "# test_dataset = CustomDataset(\n",
    "#     test_image_paths, \n",
    "#     test_mask_paths, \n",
    "#     transform=simple_transform, \n",
    "#     band=model_band, \n",
    "#     apply_super_resolution = True,\n",
    "#     scale_factor = 2)\n",
    "\n",
    "# image, mask = train_dataset[0]  # Load the first item\n",
    "# print(f\"Transformed image shape: {image.shape}, dtype: {image.dtype}\")\n",
    "# print(f\"Transformed mask shape: {mask.shape}, dtype: {mask.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Control the synchronization of Data Augmentation transforms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_augmentations(dataset, num_samples=3):\n",
    "    for i in range(num_samples):\n",
    "        image, mask = dataset[i]\n",
    "        \n",
    "        # Display input image and mask side-by-side\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image.permute(1, 2, 0))  # Convert CHW to HWC for display\n",
    "        plt.title(\"Augmented Image\")\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(mask[0], cmap='gray')  # Show mask in grayscale\n",
    "        plt.title(\"Augmented Mask\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-08 15:00:48] Loading image and mask for index 0...\n",
      "Loading image: ../5-Data_Wrangling/data_split2sr/train/input\\img(100).tif\n",
      "Loading mask: ../5-Data_Wrangling/data_split2sr/train/labels\\target(100).tif\n",
      "Image shape: torch.Size([512, 512, 4]), dtype: torch.float32\n",
      "Mask shape: torch.Size([512, 512]), dtype: torch.float32\n",
      "[2024-12-08 15:00:48] Error at index 0: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mvisualize_augmentations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 3\u001b[0m, in \u001b[0;36mvisualize_augmentations\u001b[1;34m(dataset, num_samples)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvisualize_augmentations\u001b[39m(dataset, num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[1;32m----> 3\u001b[0m         image, mask \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# Display input image and mask side-by-side\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m5\u001b[39m))\n",
      "Cell \u001b[1;32mIn[32], line 88\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Error at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[32], line 65\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     54\u001b[0m     image \u001b[38;5;241m=\u001b[39m (image \u001b[38;5;241m-\u001b[39m image_min) \u001b[38;5;241m/\u001b[39m (image_max \u001b[38;5;241m-\u001b[39m image_min)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# Reshape for MinMaxScaler and apply normalization\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#image_reshaped = image.reshape(-1, 4)\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#image_scaled = self.scaler.fit_transform(image_reshaped)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# mask = np.asarray(mask, dtype='float32')\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#mask = np.where(mask>1, 0, mask) # some images has soil annotations as well\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m mask \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Debugging: Print shapes and types\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m#print(f\"Image shape: {image.shape}, dtype: {image.dtype}\")\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m#print(f\"Mask shape: {mask.shape}, dtype: {mask.dtype}\")\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Debugging: Log the properties of the loaded image and mask\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Image shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, dtype: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "visualize_augmentations(train_dataset, num_samples=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['../5-Data_Wrangling/data_split2sr/train/input\\\\img(100).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1001).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1002).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1003).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1004).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1005).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1006).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1007).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1008).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1009).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(101).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1010).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1011).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1012).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1013).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1014).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1015).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1016).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1017).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/input\\\\img(1018).tif'],\n",
       " ['../5-Data_Wrangling/data_split2sr/train/labels\\\\target(100).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1001).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1002).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1003).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1004).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1005).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1006).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1007).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1008).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1009).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(101).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1010).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1011).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1012).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1013).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1014).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1015).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1016).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1017).tif',\n",
       "  '../5-Data_Wrangling/data_split2sr/train/labels\\\\target(1018).tif'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.image_paths[:20], train_dataset.target_paths[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {\n",
    "    'train': train_dataset, 'val': val_dataset, 'test': test_dataset\n",
    "}\n",
    "\n",
    "#dataloaders = {\n",
    "#    'train': torch.utils.data.DataLoader(train_dataset, batch_size=5, shuffle=True, num_workers=0),\n",
    "#    'val': torch.utils.data.DataLoader(val_dataset, batch_size=10, shuffle=False, num_workers=0),\n",
    "#    'test': torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=0)\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODER = 'efficientnet-b7'\n",
    "#ENCODER = 'efficientnet-b0' #for DeepLabV3+\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "CLASSES = ['solar_panel']\n",
    "ACTIVATION = 'sigmoid'\n",
    "#DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "#model = smp.Unet(\n",
    "#model = smp.DeepLabV3Plus(\n",
    "model = smp.UnetPlusPlus(\n",
    "    in_channels = 4 if use_all_bands else 1, #4 for all bands\n",
    "    encoder_name=ENCODER, \n",
    "    encoder_weights=ENCODER_WEIGHTS, \n",
    "    classes=len(CLASSES), \n",
    "    activation=ACTIVATION,\n",
    "    #decoder_atrous_rates = (6, 12, 24) # for DeepLabv3+\n",
    "    #decoder_dropout=0.3\n",
    "       \n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Devs\\pyEnv-1\\UCSD_MLBootcamp_Capstone\\5b-Run_a_Model\\5b-Model-env\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class WeightedBCELoss(nn.Module):\n",
    "    def __init__(self, pos_weight=1.0, neg_weight=1.0):\n",
    "        super(WeightedBCELoss, self).__init__()\n",
    "        self.pos_weight = pos_weight  # Weight for positive class\n",
    "        self.neg_weight = neg_weight  # Weight for negative class\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # print(f\"weights: pos {self.pos_weight} neg {self.neg_weight}\") # debugging\n",
    "        # Weighted BCE computation\n",
    "        loss = -self.pos_weight * targets * torch.log(inputs + 1e-7) - \\\n",
    "               self.neg_weight * (1 - targets) * torch.log(1 - inputs + 1e-7)\n",
    "        return loss.mean()\n",
    "\n",
    "class BCEFocalNegativeIoULoss(nn.Module):\n",
    "    def __init__(self, alpha=0.8, gamma=1.5, pos_weight=2.0, neg_weight=1.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            alpha: Weight for Focal Loss.\n",
    "            gamma: Modulating factor for Focal Loss.\n",
    "            pos_weight: Weight for positive class in BCE Loss.\n",
    "            neg_weight: Weight for negative class in BCE Loss.\n",
    "        \"\"\"\n",
    "        super(BCEFocalNegativeIoULoss, self).__init__()\n",
    "        self.bce = WeightedBCELoss(pos_weight=pos_weight, neg_weight=neg_weight)\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def focal_loss(self, inputs, targets):\n",
    "        BCE_loss = -targets * torch.log(inputs + 1e-7) - (1 - targets) * torch.log(1 - inputs + 1e-7)\n",
    "        #pt = torch.exp(-BCE_loss)  # Probability of the true class\n",
    "        pt = inputs * targets + (1 - inputs) * (1 - targets)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "        return F_loss.mean()\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        if targets.sum() == 0:  # Skip blank masks\n",
    "            return torch.tensor(0.0, requires_grad=True).to(inputs.device)\n",
    "\n",
    "        # Core loss components\n",
    "        bce_loss = self.bce(inputs, targets)\n",
    "        focal_loss = self.focal_loss(inputs, targets)\n",
    "\n",
    "        # Compute IoU for positive and negative classes\n",
    "        #preds = inputs.sigmoid()  # Apply sigmoid activation\n",
    "        preds = inputs\n",
    "        #preds = model(inputs)  # No need to apply sigmoid again if already applied in the model\n",
    "        iou_positive, mean_iou = compute_class_aware_iou(preds, targets)\n",
    "\n",
    "        # Jaccard Loss for Positive and Negative IoU\n",
    "        jaccard_loss_positive = 1.0 - iou_positive  # Positive IoU\n",
    "        jaccard_loss_negative = 1.0 - (2 * mean_iou - iou_positive)  # Derive Negative IoU\n",
    "\n",
    "        # Weighted Jaccard Loss\n",
    "        jaccard_loss = 0.85 * jaccard_loss_positive + 0.15 * jaccard_loss_negative\n",
    "\n",
    "        # Combine all losses\n",
    "        total_loss = 0.3 * bce_loss + 0.3 * focal_loss + 0.4 * jaccard_loss\n",
    "        return total_loss\n",
    "\n",
    "#loss = BCEFocalJaccardLoss(alpha=0.8, gamma=2)\n",
    "#loss = BCEFocalJaccardIoULoss(alpha=0.8, gamma=1.5)\n",
    "loss = BCEFocalNegativeIoULoss(alpha=0.8, gamma=2)\n",
    "loss_fn = loss\n",
    "\n",
    "    \n",
    "# optimizer = torch.optim.Adam([ \n",
    "#     dict(params=model.parameters(), lr=0.0006),\n",
    "#     #dict(params=model.parameters(), lr=0.00001),\n",
    "# ])\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), \n",
    "    #lr=0.0006,               \n",
    "    lr=0.0001,               \n",
    "    weight_decay=1e-6        \n",
    "    #weight_decay=0        \n",
    ")\n",
    "\n",
    "# Initialize the Global Threshold to predict sigmoid inputs\n",
    "g_threshold = 0.5\n",
    "\n",
    "\n",
    "# Adjusts every 'step_size' epochs, decreasing by 'gamma'*100 %\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "# add Warmup to the scheduler\n",
    "# num_epochs = 400\n",
    "# num_warmup_steps = 50\n",
    "\n",
    "# scheduler = get_cosine_schedule_with_warmup(\n",
    "#     optimizer,\n",
    "#     num_warmup_steps=num_warmup_steps,\n",
    "#     num_training_steps=num_epochs * len(train_loader)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### substitute SMP library to handle the trainig, validation and testing original loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, shuffle=True, num_workers=0)\n",
    "# valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=40, shuffle=False, num_workers=0)\n",
    "# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=30, shuffle=False, num_workers=0)\n",
    "\n",
    "# new batch sizes for super resolution\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=5, shuffle=True, num_workers=0, pin_memory=True)\n",
    "valid_loader = torch.utils.data.DataLoader(val_dataset, batch_size=5, shuffle=False, num_workers=0, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=5, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Device setup\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Move the model to GPU\n",
    "model = model.to(DEVICE)  # This moves your model to the GPU (or keeps it on CPU if no GPU)\n",
    "\n",
    "def compute_class_aware_iou(preds, masks, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Compute IoU for positive and negative classes with a dynamic threshold.\n",
    "    Args:\n",
    "        preds: Predicted probabilities (logits or after sigmoid).\n",
    "        masks: Ground truth masks.\n",
    "        threshold: Threshold to classify predictions (default is 0.3).\n",
    "\n",
    "    Returns:\n",
    "        iou_positive: IoU for the positive class.\n",
    "        mean_iou: Mean IoU across both classes.\n",
    "    \"\"\"\n",
    "    # Apply threshold to predictions\n",
    "    preds = (preds > threshold).int()\n",
    "    masks = masks.int()\n",
    "\n",
    "    preds_np = preds.cpu().numpy().reshape(-1)\n",
    "    masks_np = masks.cpu().numpy().reshape(-1)\n",
    "\n",
    "    # Compute IoU for positive and negative classes\n",
    "    iou_positive = jaccard_score(masks_np, preds_np, pos_label=1)\n",
    "    iou_negative = jaccard_score(masks_np, preds_np, pos_label=0)\n",
    "\n",
    "    # Mean IoU\n",
    "    mean_iou = (iou_positive + iou_negative) / 2\n",
    "    return iou_positive, mean_iou\n",
    "\n",
    "\n",
    "\n",
    "# Define training loop function\n",
    "def train_one_epoch(model, dataloader, optimizer, loss_fn, device, discard_allbkgnd = True):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    total_iou = 0\n",
    "    num_batches = 0\n",
    "    iou_metric = JaccardIndex(task='binary', threshold=0.5).to(device)\n",
    "    nb_blank = 0\n",
    "    nb_tot_img = 0\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    for images, masks in dataloader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # Check which images in the batch have all-background masks\n",
    "        valid_mask_indices = [i for i in range(masks.size(0)) if masks[i].sum() > 0]\n",
    "        \n",
    "        # number of all-background images per batch\n",
    "        nb_blank += masks.size(0) - len(valid_mask_indices)\n",
    "        nb_tot_img += masks.size(0)\n",
    "\n",
    "        # Control all background images\n",
    "        if discard_allbkgnd == False:\n",
    "            valid_mask_indices = range(masks.size(0))\n",
    "            \n",
    "        # Skip this batch if no valid masks\n",
    "        if len(valid_mask_indices) == 0:\n",
    "            print(\"Skipped batch with all all-background images.\")\n",
    "            continue  \n",
    "\n",
    "        # Filter images and masks for valid entries\n",
    "        valid_images = images[valid_mask_indices]\n",
    "        valid_masks = masks[valid_mask_indices]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Use autocast for mixed precision\n",
    "        with autocast():\n",
    "            preds = model(valid_images)\n",
    "            loss = loss_fn(preds, masks)\n",
    "\n",
    "        # Forward pass\n",
    "        # preds = model(valid_images)\n",
    "        # loss = loss_fn(preds, valid_masks)\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Scale loss and perform backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        #loss.backward()\n",
    "        #optimizer.step()\n",
    "\n",
    "        # Calculate IoU for valid images\n",
    "        total_iou += iou_metric(preds, valid_masks).item() * len(valid_mask_indices)\n",
    "        num_batches += len(valid_mask_indices)\n",
    "\n",
    "    # Avoid division by zero if all batches are skipped\n",
    "    avg_loss = epoch_loss / num_batches if num_batches > 0 else 0\n",
    "    avg_iou = total_iou / num_batches if num_batches > 0 else 0\n",
    "    print(f\"Discard 0s? {discard_allbkgnd}\\t| 0s_masks/Tot_imgs: {nb_blank}/{nb_tot_img} \\t|| Train Loss: {avg_loss:.6f} | Train IoU: {avg_iou:.3f}\")\n",
    "    return avg_loss, avg_iou\n",
    "\n",
    "\n",
    "def validate_one_epoch(model, dataloader, loss_fn, device, threshold=0.5, discard_allbkgnd=True):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_iou = 0.0\n",
    "    num_valid_images = 0\n",
    "    iou_metric = JaccardIndex(task='binary', threshold=threshold).to(device)\n",
    "    nb_blank = 0\n",
    "    nb_tot_img = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "            # Check which images in the batch have valid masks\n",
    "            valid_mask_indices = [i for i in range(masks.size(0)) if masks[i].sum() > 0]\n",
    "\n",
    "            # number of all-background images per batch\n",
    "            nb_blank += masks.size(0) - len(valid_mask_indices)\n",
    "            nb_tot_img += masks.size(0)\n",
    "\n",
    "            # Control all background images\n",
    "            if discard_allbkgnd == False:\n",
    "                valid_mask_indices = range(masks.size(0))\n",
    "                \n",
    "            # Skip this batch if no valid masks\n",
    "            if len(valid_mask_indices) == 0:\n",
    "                print(\"Skipped batch with all all-background images.\")\n",
    "                continue  \n",
    "            \n",
    "            # Filter images and masks for valid entries\n",
    "            valid_images = images[valid_mask_indices]\n",
    "            valid_masks = masks[valid_mask_indices]\n",
    "\n",
    "            preds = model(valid_images)\n",
    "            loss = loss_fn(preds, valid_masks)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Threshold predictions for metric computation\n",
    "            preds = (preds > threshold).int()\n",
    "\n",
    "            # Calculate IoU for valid images\n",
    "            total_iou += iou_metric(preds, valid_masks).item() * len(valid_mask_indices)\n",
    "            num_valid_images += len(valid_mask_indices)\n",
    "\n",
    "    avg_loss = epoch_loss / num_valid_images if num_valid_images > 0 else 0\n",
    "    avg_iou = total_iou / num_valid_images if num_valid_images > 0 else 0\n",
    "    #print(f\"0s_masks/Tot_imgs: {nb_blank}/{nb_tot_img} \\t|| Valid Loss: {avg_loss:.6f} | Valid IoU: {avg_iou:.3f}\")\n",
    "    print(f\"Discard 0s? {discard_allbkgnd}\\t| 0s_masks/Tot_imgs: {nb_blank}/{nb_tot_img} \\t|| Valid Loss: {avg_loss:.6f} | Valid IoU: {avg_iou:.3f}\")\n",
    "    return avg_loss, avg_iou\n",
    "    \n",
    "\n",
    "# Define test loop function\n",
    "def test_one_epoch(model, dataloader, loss_fn, device, threshold=0.5, discard_allbkgnd = True):\n",
    "    \"\"\"\n",
    "    Test the model for one epoch with a dynamic threshold.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    total_iou = 0.0\n",
    "    num_valid_images = 0\n",
    "    #num_batches = 0\n",
    "    iou_metric = JaccardIndex(task='binary', threshold=threshold).to(device)\n",
    "    nb_blank = 0\n",
    "    nb_tot_img = 0\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in dataloader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "                \n",
    "            # debugging\n",
    "            #print(f' deb: {j} masks.size(0) {masks.size(0)}')\n",
    "            #print(f' deb: {j} images.size(0) {masks.size(0)}')\n",
    "            \n",
    "            valid_mask_indices = [i for i in range(masks.size(0)) if masks[i].sum() > 0]\n",
    "            #print(f' deb: {j} len(valid_mask_indices) {len(valid_mask_indices)}')\n",
    "\n",
    "            # number of all-background images per batch\n",
    "            nb_blank += masks.size(0) - len(valid_mask_indices)\n",
    "            nb_tot_img += masks.size(0)\n",
    "\n",
    "            # Control all background images\n",
    "            if discard_allbkgnd == False:\n",
    "                valid_mask_indices = range(masks.size(0))\n",
    "            \n",
    "            # Skip this batch if no valid masks\n",
    "            if len(valid_mask_indices) == 0:\n",
    "                print(\"Skipped batch with all all-background images.\")\n",
    "                continue  \n",
    "            \n",
    "            # Filter images and masks for valid entries\n",
    "            valid_images = images[valid_mask_indices]\n",
    "            valid_masks = masks[valid_mask_indices]\n",
    "\n",
    "            preds = model(valid_images)\n",
    "            loss = loss_fn(preds, valid_masks)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Threshold predictions\n",
    "            preds = (preds > threshold).int()\n",
    "            \n",
    "            # Calculate IoU for valid images\n",
    "            total_iou += iou_metric(preds, valid_masks).item() * len(valid_mask_indices)\n",
    "            num_valid_images += len(valid_mask_indices)\n",
    "            \n",
    "    avg_loss = epoch_loss / num_valid_images if num_valid_images > 0 else 0\n",
    "    avg_iou = total_iou / num_valid_images if num_valid_images > 0 else 0\n",
    "    #print(f\"0s_masks/Tot_imgs: {nb_blank}/{nb_tot_img} \\t|| Test Loss:  {avg_loss:.6f} | Test IoU: {avg_iou:.3f}\")\n",
    "    print(f\"Discard 0s? {discard_allbkgnd}\\t| 0s_masks/Tot_imgs: {nb_blank}/{nb_tot_img} \\t|| Test Loss: {avg_loss:.6f} | Test IoU: {avg_iou:.3f}\")\n",
    "    return avg_loss, avg_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after last improvement before stopping.\n",
    "            min_delta (float): Minimum change in the monitored metric to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best_metric = np.inf  # Start with infinity for minimizing metrics (e.g., validation loss)\n",
    "        self.counter = 0  # Count epochs without improvement\n",
    "\n",
    "    def __call__(self, current_metric):\n",
    "        # Check if the current metric is better than the best metric\n",
    "        if current_metric < self.best_metric - self.min_delta:\n",
    "            self.best_metric = current_metric\n",
    "            self.counter = 0  # Reset counter if there is an improvement\n",
    "            return False  # Do not stop, continue training\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                return True  # Stop training\n",
    "            return False  # Continue training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-08 15:06:45] Preloading images and masks into GPU memory...\n",
      "[2024-12-08 15:06:45] Preloading complete.\n",
      "[2024-12-08 15:06:45] Preloading images and masks into GPU memory...\n",
      "[2024-12-08 15:06:45] Preloading complete.\n",
      "[2024-12-08 15:06:45] Preloading images and masks into GPU memory...\n",
      "[2024-12-08 15:06:45] Preloading complete.\n",
      "\n",
      "Starting training loop...\n",
      "Training 400 epochs...\n",
      "\n",
      "Epoch 1/400:\n",
      "[2024-12-08 15:06:46] Loading image and mask for index 115...\n",
      "Loading image: ../5-Data_Wrangling/data_split2sr/train/input\\img(163).tif\n",
      "[2024-12-08 15:06:46] Error at index 115: list index out of range\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fpere\\AppData\\Local\\Temp\\ipykernel_6384\\83172756.py:48: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 230\u001b[0m\n\u001b[0;32m    228\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[38;5;66;03m# Call the main function\u001b[39;00m\n\u001b[1;32m--> 230\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[71], line 125\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(num_epochs)\u001b[0m\n\u001b[0;32m    122\u001b[0m epoch_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 125\u001b[0m train_loss, train_iou_score \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m valid_loss, valid_iou_score \u001b[38;5;241m=\u001b[39m validate_one_epoch(model, valid_loader, loss_fn, DEVICE)\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completed. Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train IoU: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_iou_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[59], line 50\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[1;34m(model, dataloader, optimizer, loss_fn, device, discard_allbkgnd)\u001b[0m\n\u001b[0;32m     46\u001b[0m nb_tot_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     48\u001b[0m scaler \u001b[38;5;241m=\u001b[39m GradScaler()\n\u001b[1;32m---> 50\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Check which images in the batch have all-background masks\u001b[39;49;00m\n",
      "File \u001b[1;32mE:\\Devs\\pyEnv-1\\UCSD_MLBootcamp_Capstone\\5b-Run_a_Model\\5b-Model-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mE:\\Devs\\pyEnv-1\\UCSD_MLBootcamp_Capstone\\5b-Run_a_Model\\5b-Model-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mE:\\Devs\\pyEnv-1\\UCSD_MLBootcamp_Capstone\\5b-Run_a_Model\\5b-Model-env\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[32], line 88\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mH:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Error at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "Cell \u001b[1;32mIn[32], line 34\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Retrieve preloaded image and mask\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# image = self.images[index]\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# mask = self.masks[index]\u001b[39;00m\n\u001b[0;32m     32\u001b[0m  \u001b[38;5;66;03m# Debugging: Add print statements for image and mask paths\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_paths[index]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading mask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmasks\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m image \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimages[index], cv2\u001b[38;5;241m.\u001b[39mIMREAD_UNCHANGED)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n\u001b[0;32m     36\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks[index], cv2\u001b[38;5;241m.\u001b[39mIMREAD_UNCHANGED)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32))\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.profiler\n",
    "\n",
    "def main(num_epochs):\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    test_losses = []\n",
    "    train_ious = []\n",
    "    valid_ious = []\n",
    "    test_ious = []\n",
    "\n",
    " \n",
    "    # Initialize dataset and DataLoader\n",
    "    train_dataset = CustomDataset(train_image_paths, train_mask_paths, transform=augmentation_transform, band=model_band)\n",
    "    val_dataset = CustomDataset(val_image_paths, val_mask_paths, transform=simple_transform, band=model_band)\n",
    "    test_dataset = CustomDataset(test_image_paths, test_mask_paths, transform=simple_transform, band=model_band)\n",
    "\n",
    "    # Wrap train_dataset with ProfileIterDataPipe for profiling\n",
    "    #profiled_train_dataset = ProfileIterDataPipe(train_dataset)\n",
    "\n",
    "    # print(\"[INFO] Profiling DataLoader performance...\")\n",
    "    # # Profile DataLoader\n",
    "    # print(\"[INFO] Profiling DataLoader performance...\")\n",
    "    # profiled_train_loader = DataLoader(\n",
    "    #     profiled_train_dataset,\n",
    "    #     batch_size=2,  # Use small batch size for debugging\n",
    "    #     shuffle=True,\n",
    "    #     num_workers=2,  # Change num_workers to fit your CPU cores\n",
    "    #     pin_memory=torch.cuda.is_available()\n",
    "    # )\n",
    "\n",
    "    # # Process a few batches to profile\n",
    "    # for i, (images, masks) in enumerate(profiled_train_loader):\n",
    "    #     print(f\"Profiling Batch {i + 1}:\")\n",
    "    #     print(f\" - Image tensor shape: {images.shape}, dtype: {images.dtype}\")\n",
    "    #     print(f\" - Mask tensor shape: {masks.shape}, dtype: {masks.dtype}\")\n",
    "    #     if i >= 4:  # Profile first 5 batches only\n",
    "    #         break\n",
    "\n",
    "    # Reinitialize train_loader after profiling\n",
    "    # print(\"[INFO] Reverting to the standard DataLoader for training...\")\n",
    "    # train_loader = DataLoader(\n",
    "    #     train_dataset,\n",
    "    #     batch_size=2,  # Original batch size for training\n",
    "    #     shuffle=True,\n",
    "    #     num_workers=0,  # Same workers as above\n",
    "    #     pin_memory=torch.cuda.is_available()\n",
    "    # )\n",
    "    \n",
    "    # Batch sizes for super resolution\n",
    "    #train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=0, pin_memory=True)\n",
    "    # valid_loader = torch.utils.data.DataLoader(\n",
    "    #     val_dataset, \n",
    "    #     batch_size=2, \n",
    "    #     shuffle=False, \n",
    "    #     num_workers=0, \n",
    "    #     pin_memory=True)\n",
    "    \n",
    "    # test_loader = torch.utils.data.DataLoader(\n",
    "    #     test_dataset, \n",
    "    #     batch_size=2, \n",
    "    #     shuffle=False, \n",
    "    #     num_workers=0, \n",
    "    #     pin_memory=True)\n",
    "\n",
    "    # Define the model, loss function, optimizer, and scheduler\n",
    "    model = smp.UnetPlusPlus(\n",
    "        in_channels=4 if use_all_bands else 1,\n",
    "        encoder_name=ENCODER,\n",
    "        encoder_weights=ENCODER_WEIGHTS,\n",
    "        classes=len(CLASSES),\n",
    "        activation=ACTIVATION\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    loss_fn = BCEFocalNegativeIoULoss(alpha=0.8, gamma=2)\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        model.parameters(),\n",
    "        lr=0.0001,\n",
    "        weight_decay=1e-6\n",
    "    )\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "    early_stopping = EarlyStopping(patience=5, min_delta=0.01)\n",
    "\n",
    "    \n",
    "    # Force to include the test set loss and score metric into the training loop\n",
    "    include_test = False\n",
    "\n",
    "    # Save the model's parameters\n",
    "    model_filename = './models/unetpp_effb7.pth'\n",
    "    \n",
    "    max_score = float('inf')  # Initialize with a high value to store the best validation loss\n",
    "    \n",
    "    # Initialize early stopping\n",
    "    #early_stopping = EarlyStopping(patience=20, min_delta=0.00001)\n",
    "   \n",
    "    tic = time.time()\n",
    "    print(\"\\nStarting training loop...\")\n",
    "    \n",
    "    # Ensure loss_fn is defined globally or passed correctly\n",
    "    #global loss_fn  # Add this line if loss_fn is already defined globally\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Training {num_epochs} epochs...\")\n",
    "    total_train_time = 0\n",
    "\n",
    "    with torch.profiler.profile(\n",
    "        activities=[\n",
    "            torch.profiler.ProfilerActivity.CPU,\n",
    "            torch.profiler.ProfilerActivity.CUDA\n",
    "        ],\n",
    "        on_trace_ready=torch.profiler.tensorboard_trace_handler('./log'),\n",
    "        record_shapes=True,\n",
    "        profile_memory=True\n",
    "    ) as prof:\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_start = time.time()\n",
    "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}:\")\n",
    "            \n",
    "            train_loss, train_iou_score = train_one_epoch(model, train_loader, loss_fn, optimizer, DEVICE)\n",
    "            valid_loss, valid_iou_score = validate_one_epoch(model, valid_loader, loss_fn, DEVICE)\n",
    "    \n",
    "            print(f\"Epoch {epoch + 1} completed. Train Loss: {train_loss:.4f}, Train IoU: {train_iou_score:.4f}\")\n",
    "            print(f\"Validation Loss: {valid_loss:.4f}, Validation IoU: {valid_iou_score:.4f}\")\n",
    "    \n",
    "            # Update scheduler\n",
    "            scheduler.step(valid_loss)\n",
    "    \n",
    "            # Save the best model\n",
    "            if valid_loss < scheduler.best:\n",
    "                torch.save(model.state_dict(), \"best_model.pth\")\n",
    "                print(\"Model saved.\")\n",
    "    \n",
    "            # Check early stopping\n",
    "            if early_stopping(valid_loss):\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    \n",
    "            total_train_time += time.time() - epoch_start\n",
    "            \n",
    "        # for epoch in range(num_epochs):\n",
    "        #     print(f'\\nEpoch: {epoch}')\n",
    "            \n",
    "        #     epoch_start = time.time()\n",
    "            \n",
    "        #     # Training\n",
    "        #     model.train()\n",
    "        #     total_train_time = 0\n",
    "        #     for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "        #         batch_start = time.time()\n",
    "                \n",
    "        #         # Data to GPU\n",
    "        #         data_transfer_start = time.time()\n",
    "        #         images, masks = images.to(DEVICE), masks.to(DEVICE)\n",
    "        #         data_transfer_time = time.time() - data_transfer_start\n",
    "                \n",
    "        #         # Forward pass\n",
    "        #         forward_start = time.time()\n",
    "        #         outputs = model(images)\n",
    "        #         forward_time = time.time() - forward_start\n",
    "                \n",
    "        #         # Loss computation\n",
    "        #         loss_start = time.time()\n",
    "        #         loss = loss_fn(outputs, masks)\n",
    "        #         loss_time = time.time() - loss_start\n",
    "                \n",
    "        #         # Backward pass and optimization\n",
    "        #         backward_start = time.time()\n",
    "        #         optimizer.zero_grad()\n",
    "        #         loss.backward()\n",
    "        #         optimizer.step()\n",
    "        #         backward_time = time.time() - backward_start\n",
    "                \n",
    "        #         batch_time = time.time() - batch_start\n",
    "        #         total_train_time += batch_time\n",
    "    \n",
    "        #         print(f\"Batch {batch_idx}: Data transfer {data_transfer_time:.4f}s, \"\n",
    "        #               f\"Forward {forward_time:.4f}s, Loss {loss_time:.4f}s, Backward {backward_time:.4f}s, \"\n",
    "        #               f\"Total {batch_time:.4f}s\")\n",
    "            \n",
    "            train_loss, train_iou_score = train_one_epoch(model, train_loader, optimizer, loss_fn=loss_fn, device=DEVICE, discard_allbkgnd=True)\n",
    "            train_losses.append(train_loss)\n",
    "            train_ious.append(train_iou_score)\n",
    "            \n",
    "            # Validation\n",
    "            valid_loss, valid_iou_score = validate_one_epoch(model, valid_loader, loss_fn=loss_fn, device=DEVICE, discard_allbkgnd=True)\n",
    "            valid_losses.append(valid_loss)\n",
    "            valid_ious.append(valid_iou_score)\n",
    "        \n",
    "            # # Check early stopping criteria with the validation loss\n",
    "            # if early_stopping(valid_loss):\n",
    "            #     print(f\"Stopping at epoch {epoch}\")\n",
    "            #     break  \n",
    "    \n",
    "            # if include_test:\n",
    "            #     # Run testing\n",
    "            #     test_loss, test_iou_score = test_one_epoch(model, test_loader, loss_fn=loss_fn, device=DEVICE, discard_allbkgnd=True)\n",
    "            #     test_losses.append(test_loss)\n",
    "            #     test_ious.append(test_iou_score)\n",
    "            \n",
    "            # # Update the learning rate\n",
    "            # scheduler.step(valid_loss)\n",
    "            \n",
    "            # Save the model if validation loss improves\n",
    "            if valid_loss < max_score:\n",
    "                max_score = valid_loss\n",
    "                torch.save(model, model_filename)\n",
    "                print('Model saved!')\n",
    "            \n",
    "            # epoch_time = time.time() - epoch_start\n",
    "            # print(f\"Epoch {epoch} completed in {epoch_time:.2f} seconds. Total training time: {total_train_time:.2f} seconds.\")\n",
    "    \n",
    "            print(f\"Total training time: {total_train_time / 60:.2f} minutes.\")\n",
    "\n",
    "    # toc = time.time()\n",
    "    # elapsed_time = toc - tic\n",
    "    # print(f\"\\nTraining completed in {elapsed_time // 60:.0f} minutes and {elapsed_time % 60:.2f} seconds.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the start method to spawn\n",
    "    mp.set_start_method(\"spawn\", force=True)\n",
    "\n",
    "    num_epochs = 400\n",
    "    # Call the main function\n",
    "    main(num_epochs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot metrics after training\n",
    "plt.figure(figsize=(12, 3))\n",
    "\n",
    "# Plot training/validation losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label=\"Training Loss\")\n",
    "plt.plot(valid_losses, label=\"Validation Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.title(\"Losses over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Plot IoU for validation and test sets\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_ious, label=\"Training IoU\")\n",
    "plt.plot(valid_ious, label=\"Validation IoU\")\n",
    "plt.plot(test_ious, label=\"Test IoU\")\n",
    "plt.title(\"IoU over Epochs\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"IoU\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DLV3\n",
    "#model = torch.load('datasets/solar_panel/models_new/test.pth')\n",
    "#model = torch.load('./models/dlv3_effb0.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/dlv3_r101.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/dlv3_r50.pth')\n",
    "\n",
    "# UNET\n",
    "#model = torch.load('datasets/solar_panel/models_new/unet_r101.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/unet_effb0.pth')\n",
    "##model = torch.load('./models/unet_effb7.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/unet_r50.pth')\n",
    "\n",
    "# UNET++\n",
    "model = torch.load('./models/unetpp_effb7.pth')\n",
    "\n",
    "#PSPNet\n",
    "#model = torch.load('datasets/solar_panel/models_new/psp_effb7_at.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/psp_effb0.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/psp_r101.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/psp_r50.pth')\n",
    "\n",
    "# FPN\n",
    "#model = torch.load('datasets/solar_panel/models_new/fpn_effb7.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/fpn_effb0.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/fpn_r101.pth')\n",
    "#model = torch.load('datasets/solar_panel/models_new/fpn_r50.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVAL MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torchmetrics import JaccardIndex\n",
    "\n",
    "# Ensure no gradients are calculated, as this is evaluation\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Fetch a batch from the test loader\n",
    "    inp, lab = next(iter(test_loader))\n",
    "    inp = inp.to(DEVICE)\n",
    "    lab = lab.to(DEVICE)\n",
    "\n",
    "    # Predict\n",
    "    pred = model(inp)\n",
    "    #pred = (pred.sigmoid() > 0.5).float()\n",
    "    #pred = pred.sigmoid()  \n",
    "\n",
    "    # Reshape if necessary to match [batch_size, 1, height, width]\n",
    "    if pred.shape[1] != 1:\n",
    "        pred = pred.unsqueeze(1)\n",
    "\n",
    "    if lab.shape[1] != 1:\n",
    "        lab = lab.unsqueeze(1)\n",
    "\n",
    "    # Calculate IoU score for the batch\n",
    "    iou_metric = JaccardIndex(task='binary', threshold=0.5).to(DEVICE)  # Use binary IoU for evaluation\n",
    "    iou_score = iou_metric(pred, lab)\n",
    "\n",
    "    print(f\"Sample IoU Score: {iou_score.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy, IoU, and F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
    "\n",
    "# # Flatten the labels and predictions for metric computation\n",
    "# lbl = lab.cpu().numpy().reshape(-1)  # Convert the ground truth mask to a 1D array\n",
    "# target = pred.cpu().numpy().reshape(-1)  # Convert the predicted mask to a 1D array\n",
    "\n",
    "# # Check value distributions in lbl and target\n",
    "# #print(f\"Label distribution: {np.unique(lbl, return_counts=True)}\")\n",
    "# #print(f\"Prediction distribution: {np.unique(target, return_counts=True)}\")\n",
    "\n",
    "# # Convert predictions to binary format at two different thresholds\n",
    "\n",
    "# target_25 = np.where(target > 0.25, 1, 0)\n",
    "# target_50 = np.where(target > 0.5, 1, 0)\n",
    "# target_75 = np.where(target > 0.75, 1, 0)\n",
    "\n",
    "# # Ensure ground truth is binary\n",
    "# lbl = np.where(lbl > 0.5, 1, 0)\n",
    "\n",
    "# def compute_metrics(label, target_25, target_50, target_75):\n",
    "#     # Compute accuracy at different thresholds\n",
    "#     acc_25 = accuracy_score(label, target_25)\n",
    "#     acc_50 = accuracy_score(label, target_50)\n",
    "#     acc_75 = accuracy_score(label, target_75)\n",
    "    \n",
    "#     # Compute IoU (Jaccard score) at different thresholds\n",
    "#     iou_25 = jaccard_score(label, target_25)\n",
    "#     iou_50 = jaccard_score(label, target_50)\n",
    "#     iou_75 = jaccard_score(label, target_75)\n",
    "    \n",
    "#     # Compute F1-score at different thresholds\n",
    "#     f_25 = f1_score(label, target_25)\n",
    "#     f_50 = f1_score(label, target_50)\n",
    "#     f_75 = f1_score(label, target_75)\n",
    "    \n",
    "#     # Display results\n",
    "#     print('Thresholds: \\t 25% \\t| 50% \\t| 75%')\n",
    "#     print(40*'-')\n",
    "#     print('Accuracy:\\t', round(acc_25 * 100, 2), '|', round(acc_50 * 100, 2), '|', round(acc_75 * 100, 2))\n",
    "#     print('IoU:\\t\\t', round(iou_25 * 100, 2), '|', round(iou_50 * 100, 2), '|', round(iou_75 * 100, 2))\n",
    "#     print('F-score:\\t', round(f_25 * 100, 2), '|', round(f_50 * 100, 2), '|', round(f_75 * 100, 2))\n",
    "\n",
    "# # Compute and display the metrics\n",
    "# compute_metrics(lbl, target_25, target_50, target_75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# def compute_confusion_matrix(model, test_loader, device, threshold=0.5):\n",
    "#     \"\"\"\n",
    "#     Compute the confusion matrix for predictions with a dynamic threshold.\n",
    "#     \"\"\"\n",
    "#     model.eval()\n",
    "#     all_preds = []\n",
    "#     all_masks = []\n",
    "\n",
    "#     nb_of_images_eval = 0\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, masks in test_loader:\n",
    "            \n",
    "#             # Skip blank masks\n",
    "#             if masks.sum() == 0:\n",
    "#                 continue  \n",
    "                \n",
    "#             images = images.to(device)\n",
    "#             masks = masks.to(device)\n",
    "\n",
    "#             preds = model(images)\n",
    "\n",
    "#             # Threshold predictions\n",
    "#             preds = (preds > threshold).int()\n",
    "\n",
    "#             all_preds.append(preds.cpu().numpy().ravel())\n",
    "#             all_masks.append(masks.cpu().numpy().ravel())\n",
    "\n",
    "#             nb_of_images_eval += 1\n",
    "\n",
    "#     all_preds = np.concatenate(all_preds)\n",
    "#     all_masks = np.concatenate(all_masks)\n",
    "\n",
    "#     # Compute confusion matrix\n",
    "#     cm = confusion_matrix(all_masks, all_preds, labels=[0, 1])\n",
    "#     return cm, nb_of_images_eval\n",
    "\n",
    "\n",
    "# def display_traditional_confusion_matrix_with_metrics(cm, nb_of_images):\n",
    "#     \"\"\"\n",
    "#     Display the confusion matrix with the traditional layout and print additional metrics.\n",
    "#     Args:\n",
    "#         cm: Confusion matrix (2x2 for binary classification).\n",
    "#     \"\"\"\n",
    "    \n",
    "#     # New labels for the classes\n",
    "#     labels = [\"Background\", \"PV\"]\n",
    "\n",
    "#     # Extract values from confusion matrix\n",
    "#     TN = cm[0, 0]  # True Negative\n",
    "#     FP = cm[0, 1]  # False Positive\n",
    "#     FN = cm[1, 0]  # False Negative\n",
    "#     TP = cm[1, 1]  # True Positive\n",
    "\n",
    "#     # Calculate metrics\n",
    "#     accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "#     recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity (Recall)\n",
    "#     specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # True Negative Rate\n",
    "#     precision = TP / (TP + FP) if (TP + FP) > 0 else 0  # Positive Predictive Value\n",
    "#     f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "#     IoU = TP / (TP + FN + FP) if (TP + FN + FP) > 0 else 0  # IoU\n",
    "\n",
    "#     # Print metrics\n",
    "#     print(f\"\\nNb of images computed: {nb_of_images}\")\n",
    "#     print(f\"TP:{TP}\\tTN:{TN}\\tFP:{FP}\\t\\tFN:{FN}\")\n",
    "#     print(70*'-')\n",
    "#     print(\"\\n\")\n",
    "#     print(f\"Accuracy:     {accuracy:.4f}\\t               (TP + TN) / (TP + TN + FP + FN)\")\n",
    "#     print(f\"Recall:       {recall:.4f}\\t                      TP / (TP + FN)\")\n",
    "#     print(f\"Specificity:  {specificity:.4f}\\t                      TN / (TN + FP)\")\n",
    "#     print(f\"Precision:    {precision:.4f}\\t                      TP / (TP + FP)\")\n",
    "#     print(f\"F1-Score:     {f1_score:.4f}\\t    (2*precision*recall) / (precision + recall)\")\n",
    "#     print(f\"IoU:          {IoU:.4f}\\t                      TP / (TP + FN + FP)\")\n",
    "#     print(\"\\n\\n\")\n",
    "    \n",
    "#     # Display the confusion matrix\n",
    "#     disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "#     disp.plot(cmap=plt.cm.Blues)\n",
    "#     plt.title(\"Confusion Matrix\")\n",
    "#     plt.xlabel(\"Predicted label\")\n",
    "#     plt.ylabel(\"True label\")\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# # Example usage:\n",
    "# cm, nb_of_images = compute_confusion_matrix(model, test_loader, DEVICE)\n",
    "# display_traditional_confusion_matrix_with_metrics(cm, nb_of_images)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHOW PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import jaccard_score\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import torch\n",
    "\n",
    "# Ensure the output directory is cleared and exists\n",
    "output_dir = \"imgs\"\n",
    "\n",
    "# Clear the output directory if it exists\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)  # Delete all files and the directory\n",
    "os.makedirs(output_dir, exist_ok=True)  # Create a fresh directory\n",
    "\n",
    "\n",
    "actual_img_count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    for data in test_loader:\n",
    "        inp, lab = data\n",
    "\n",
    "        inp = inp.to(DEVICE)\n",
    "        lab = lab.to(DEVICE)\n",
    "        pred = model(inp) \n",
    "\n",
    "        #print(len(inp))\n",
    "        \n",
    "        # Loop through the batch\n",
    "        for i in range(len(inp)):\n",
    "            iou_score = 0\n",
    "            \n",
    "            # Extract and process the ground truth and input image\n",
    "            lab_unit = lab[i, 0, :, :].cpu().numpy()  # Take single channel for ground truth\n",
    "            inp_unit = inp[i].cpu().numpy()  # Extract input and move to CPU\n",
    "            inp_unit = np.transpose(inp_unit[:3], (1, 2, 0))  # Take RGB channels, adjust to HxWxC\n",
    "            \n",
    "            # Process prediction and calculate IoU score\n",
    "            pred_img = pred[i, 0, :, :].cpu().numpy()  # Single channel prediction\n",
    "            #pred_img = np.where(pred_img > 0.5, 1, 0)  # Threshold to binary\n",
    "            pred_img = np.where(pred_img > g_threshold, 1, 0)\n",
    "            \n",
    "            iou_score = jaccard_score(lab_unit.reshape(-1), pred_img.reshape(-1), zero_division=0)\n",
    "\n",
    "            # Plot images\n",
    "            NUM_ROWS = 1\n",
    "            IMGs_IN_ROW = 3\n",
    "            f, ax = plt.subplots(NUM_ROWS, IMGs_IN_ROW, figsize=(10, 10))\n",
    "\n",
    "            #ax[0].imshow(inp_unit / 3000)  # Adjust scale as needed for input display\n",
    "            ax[0].imshow((inp_unit - inp_unit.min()) / (inp_unit.max() - inp_unit.min()))  # Normalize for display\n",
    "            ax[1].imshow(pred_img, cmap='binary_r')\n",
    "            ax[2].imshow(lab_unit, cmap='binary_r')\n",
    "\n",
    "            ax[0].set_title(f'Original Image | {actual_img_count + 1}')\n",
    "            ax[1].set_title(f'Prediction | {actual_img_count + 1}')\n",
    "            ax[2].set_title(f'Ground Truth | {actual_img_count + 1}')\n",
    "\n",
    "            # Remove tick labels for a cleaner plot\n",
    "            for a in ax:\n",
    "                a.set_yticklabels([])\n",
    "                a.set_xticklabels([])\n",
    "\n",
    "            print(f'ID: {actual_img_count + 1} | IoU: {round(iou_score, 3)}')\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save selected images\n",
    "            if actual_img_count in [15, 22, 29]:\n",
    "                plt.savefig(f'imgs/img{actual_img_count}.png', dpi=500, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()\n",
    "            \n",
    "            actual_img_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import seaborn as sns\n",
    "\n",
    "# def compute_confusion_matrix_with_distributions(model, test_loader, device):\n",
    "#     \"\"\"\n",
    "#     Compute the confusion matrix for all pixels in the test set.\n",
    "#     Args:\n",
    "#         model: Trained segmentation model.\n",
    "#         test_loader: DataLoader for the test set.\n",
    "#         device: Device ('cuda' or 'cpu').\n",
    "\n",
    "#     Returns:\n",
    "#         cm: Confusion matrix (2x2 for binary classification).\n",
    "#     \"\"\"\n",
    "#     model.eval()  # Set model to evaluation mode\n",
    "#     all_preds = []\n",
    "#     all_masks = []\n",
    "\n",
    "#     nb_of_images_eval = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         for images, masks in test_loader:\n",
    "#             # Ensure we're using only test images\n",
    "#             assert len(images) > 0, \"No images found in test_loader.\"\n",
    "            \n",
    "#             images = images.to(device)\n",
    "#             masks = masks.to(device)\n",
    "\n",
    "#             # Get predictions\n",
    "#             preds = model(images)\n",
    "\n",
    "#             # Ensure predictions and masks have the same spatial dimensions\n",
    "#             assert preds.shape == masks.shape, f\"Shape mismatch: preds {preds.shape}, masks {masks.shape}\"\n",
    "            \n",
    "#             # Flatten predictions and masks for confusion matrix computation\n",
    "#             all_preds.append(preds.cpu().numpy().ravel())\n",
    "#             all_masks.append(masks.cpu().numpy().ravel())\n",
    "\n",
    "#             nb_of_images_eval += 1\n",
    "\n",
    "#     # Concatenate all predictions and masks\n",
    "#     all_preds = np.concatenate(all_preds)\n",
    "#     all_masks = np.concatenate(all_masks)\n",
    "\n",
    "#     # Debug: Check final shapes\n",
    "#     print(f\"Final shapes - all_preds: {all_preds.shape}, all_masks: {all_masks.shape}\")\n",
    "#     assert len(all_preds) == len(all_masks), f\"Length mismatch: preds {len(all_preds)}, masks {len(all_masks)}\"\n",
    "\n",
    "#     # Compute confusion matrix\n",
    "#     binary_preds = (all_preds > 0.5).astype(int)\n",
    "    \n",
    "#     cm = confusion_matrix(all_masks, binary_preds, labels=[0, 1])\n",
    " \n",
    "#     # Separate probabilities for positive and negative classes\n",
    "#     pos_probs = all_preds[all_masks == 1]  # Positive class (PV)\n",
    "#     neg_probs = all_preds[all_masks == 0]  # Negative class (Background)\n",
    "\n",
    "#     return cm, pos_probs, neg_probs, nb_of_images_eval\n",
    "\n",
    "\n",
    "def compute_confusion_matrix_with_distributions(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    Compute the confusion matrix for all pixels in the test set across all batches.\n",
    "    Args:\n",
    "        model: Trained segmentation model.\n",
    "        test_loader: DataLoader for the test set.\n",
    "        device: Device ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "        cm: Confusion matrix (2x2 for binary classification).\n",
    "        pos_probs: Predicted probabilities for the positive class (PV).\n",
    "        neg_probs: Predicted probabilities for the negative class (Background).\n",
    "        nb_of_images_eval: Total number of images evaluated.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_masks = []\n",
    "\n",
    "    nb_of_images_eval = 0\n",
    "\n",
    "    # Debug: Check the dataset size\n",
    "    print(f\"Test loader dataset size: {len(test_loader.dataset)}\")\n",
    "    print(f\"Batch size: {test_loader.batch_size}, Total batches: {len(test_loader)}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, masks) in enumerate(test_loader):\n",
    "            # Ensure the batch contains images\n",
    "            if len(images) == 0:\n",
    "                print(f\"Skipped empty batch {batch_idx + 1}/{len(test_loader)}.\")\n",
    "                continue\n",
    "\n",
    "            # Debug: Print batch size\n",
    "            print(f\"Processing batch {batch_idx + 1}/{len(test_loader)}: {len(images)} images.\")\n",
    "\n",
    "            # Move images and masks to the device\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            # Get predictions\n",
    "            preds = model(images)\n",
    "\n",
    "            # Ensure predictions and masks have consistent shapes\n",
    "            if preds.shape != masks.shape:\n",
    "                print(f\"Shape mismatch in batch {batch_idx + 1}: preds {preds.shape}, masks {masks.shape}\")\n",
    "                continue  # Skip batch with inconsistent shapes\n",
    "\n",
    "            # Debug: Print shapes of predictions and masks\n",
    "            print(f\"Batch {batch_idx + 1} shapes - preds: {preds.shape}, masks: {masks.shape}\")\n",
    "\n",
    "            # Flatten predictions and masks for confusion matrix computation\n",
    "            preds_flat = preds.cpu().numpy().ravel()\n",
    "            masks_flat = masks.cpu().numpy().ravel()\n",
    "\n",
    "            # Debug: Print flattened shapes\n",
    "            print(f\"Flattened batch {batch_idx + 1} shapes - preds: {preds_flat.shape}, masks: {masks_flat.shape}\")\n",
    "\n",
    "            # Append the flattened predictions and masks\n",
    "            all_preds.append(preds_flat)\n",
    "            all_masks.append(masks_flat)\n",
    "\n",
    "            nb_of_images_eval += len(images)\n",
    "\n",
    "    # Concatenate all predictions and masks across all batches\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_masks = np.concatenate(all_masks)\n",
    "\n",
    "    # Debug: Print final concatenated shapes\n",
    "    print(f\"Final concatenated shapes - all_preds: {all_preds.shape}, all_masks: {all_masks.shape}\")\n",
    "    assert len(all_preds) == len(all_masks), (\n",
    "        f\"Length mismatch after processing all batches: preds {len(all_preds)}, masks {len(all_masks)}\"\n",
    "    )\n",
    "\n",
    "    # Convert probabilities to binary predictions (threshold = 0.5)\n",
    "    binary_preds = (all_preds > 0.5).astype(int)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_masks, binary_preds, labels=[0, 1])\n",
    "\n",
    "    # Separate probabilities for positive and negative classes\n",
    "    pos_probs = all_preds[all_masks == 1]  # Positive class (PV)\n",
    "    neg_probs = all_preds[all_masks == 0]  # Negative class (Background)\n",
    "\n",
    "    return cm, pos_probs, neg_probs, nb_of_images_eval\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "def display_confusion_matrix_with_metrics_and_distributions(cm, pos_probs, neg_probs, nb_of_images_eval):\n",
    "    \"\"\"\n",
    "    Display the confusion matrix with the traditional layout and print additional metrics.\n",
    "    Args:\n",
    "        cm: Confusion matrix (2x2 for binary classification).\n",
    "    \"\"\"\n",
    "    \n",
    "    # New labels for the classes\n",
    "    labels = [\"Background\", \"PV\"]\n",
    "\n",
    "    # Extract values from confusion matrix\n",
    "    TN = cm[0, 0]  # True Negative\n",
    "    FP = cm[0, 1]  # False Positive\n",
    "    FN = cm[1, 0]  # False Negative\n",
    "    TP = cm[1, 1]  # True Positive\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity (Recall)\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0  # True Negative Rate\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0  # Positive Predictive Value\n",
    "    f1_score = (2 * precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    IoU = TP / (TP + FN + FP) if (TP + FN + FP) > 0 else 0  # IoU\n",
    "\n",
    "    # Print metrics\n",
    "    print(70*'-')\n",
    "    print(f\"TP:{TP}\\tTN:{TN}\\tFP:{FP}\\t\\tFN:{FN}\")\n",
    "    print(70*'-')\n",
    "    print(\"\\n\")\n",
    "    print(f\"Accuracy:     {accuracy:.4f}\\t               (TP + TN) / (TP + TN + FP + FN)\")\n",
    "    print(f\"Recall:       {recall:.4f}\\t                      TP / (TP + FN)\")\n",
    "    print(f\"Specificity:  {specificity:.4f}\\t                      TN / (TN + FP)\")\n",
    "    print(f\"Precision:    {precision:.4f}\\t                      TP / (TP + FP)\")\n",
    "    print(f\"F1-Score:     {f1_score:.4f}\\t    (2*precision*recall) / (precision + recall)\")\n",
    "    print(f\"IoU:          {IoU:.4f}\\t                      TP / (TP + FN + FP)\")\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "    # Display the confusion matrix\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=plt.cm.Blues, ax=axes[0], colorbar=False)\n",
    "    axes[0].set_title(\"Confusion Matrix\")\n",
    "    axes[0].set_xlabel(\"Predicted label\")\n",
    "    axes[0].set_ylabel(\"True label\")\n",
    "\n",
    "    # Plot distributions of predicted probabilities\n",
    "    sns.kdeplot(neg_probs, fill=True, color=\"green\", alpha=0.5, label=\"Negative (Background)\", ax=axes[1])\n",
    "    sns.kdeplot(pos_probs, fill=True, color=\"blue\", alpha=0.5, label=\"Positive (PV)\", ax=axes[1])\n",
    "    \n",
    "    # Add a threshold line\n",
    "    axes[1].axvline(0.5, color=\"black\", linestyle=\"--\", label=\"Threshold\")\n",
    "    \n",
    "    # Set titles and labels\n",
    "    axes[1].set_title(\"Predicted Probability Distributions\")\n",
    "    axes[1].set_xlabel(\"Predicted Probability\")\n",
    "    axes[1].set_ylabel(\"Density\")\n",
    "    \n",
    "    # Add legend\n",
    "    axes[1].legend()\n",
    "\n",
    "\n",
    "# \n",
    "cm, pos_probs, neg_probs, nb_of_images_eval = compute_confusion_matrix_with_distributions(model, test_loader, DEVICE)\n",
    "display_confusion_matrix_with_metrics_and_distributions(cm, pos_probs, neg_probs, nb_of_images_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, pos_probs, neg_probs, nb_of_images_eval = compute_confusion_matrix_with_distributions(model, valid_loader, DEVICE)\n",
    "display_confusion_matrix_with_metrics_and_distributions(cm, pos_probs, neg_probs, nb_of_images_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_probability_distribution_zoom(pos_probs, neg_probs, zoom_ylim=(0, 5), threshold=0.5, bins=200):\n",
    "    \"\"\"\n",
    "    Plot the predicted probability distributions with a zoomed-in y-axis using histograms with more bins.\n",
    "    Args:\n",
    "        pos_probs: Predicted probabilities for the positive class (PV).\n",
    "        neg_probs: Predicted probabilities for the negative class (Background).\n",
    "        zoom_ylim: Tuple for y-axis limits (default is (0, 5)).\n",
    "        threshold: Threshold value to separate classes (default is 0.5).\n",
    "        bins: Number of bins for the histogram (default is 100).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Define bin edges to ensure alignment of histograms\n",
    "    bin_edges = np.linspace(0, 1, bins)\n",
    "\n",
    "    # Plot negative probabilities\n",
    "    plt.hist(neg_probs, bins=bin_edges, color=\"green\", alpha=0.5, label=\"Negative (Background)\", density=False)\n",
    "\n",
    "    # Plot positive probabilities\n",
    "    plt.hist(pos_probs, bins=bin_edges, color=\"blue\", alpha=0.5, label=\"Positive (PV)\", density=False)\n",
    "\n",
    "    # Add a threshold line\n",
    "    plt.axvline(threshold, color=\"black\", linestyle=\"--\", label=f\"Threshold ({threshold})\")\n",
    "\n",
    "    # Set titles and labels\n",
    "    plt.title(f\"Zoomed Predicted Probability Distributions with {bins} Bins\")\n",
    "    plt.xlabel(\"Predicted Probability\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.ylim(zoom_ylim)  # Adjust the y-axis limits to zoom in\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_probability_distribution_zoom(pos_probs, neg_probs, zoom_ylim=(0, 20000), bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, f1_score\n",
    "\n",
    "# Flatten the labels and predictions for metric computation\n",
    "lbl = lab.cpu().numpy().reshape(-1)  # Convert the ground truth mask to a 1D array\n",
    "target = pred.cpu().numpy().reshape(-1)  # Convert the predicted mask to a 1D array\n",
    "\n",
    "# Check value distributions in lbl and target\n",
    "#print(f\"Label distribution: {np.unique(lbl, return_counts=True)}\")\n",
    "#print(f\"Prediction distribution: {np.unique(target, return_counts=True)}\")\n",
    "\n",
    "# Convert predictions to binary format at two different thresholds\n",
    "\n",
    "\n",
    "target_1 = 0.45\n",
    "target_2 = 0.46\n",
    "target_3 = 0.47\n",
    "\n",
    "threshold_1 = np.where(target > target_1, 1, 0)\n",
    "threshold_2 = np.where(target > target_2, 1, 0)\n",
    "threshold_3 = np.where(target > target_3, 1, 0)\n",
    "\n",
    "# Ensure ground truth is binary\n",
    "lbl = np.where(lbl > 0.5, 1, 0)\n",
    "\n",
    "def compute_metrics(label, target_25, target_50, target_75):\n",
    "    # Compute accuracy at different thresholds\n",
    "    acc_25 = accuracy_score(label, target_25)\n",
    "    acc_50 = accuracy_score(label, target_50)\n",
    "    acc_75 = accuracy_score(label, target_75)\n",
    "    \n",
    "    # Compute IoU (Jaccard score) at different thresholds\n",
    "    iou_25 = jaccard_score(label, target_25)\n",
    "    iou_50 = jaccard_score(label, target_50)\n",
    "    iou_75 = jaccard_score(label, target_75)\n",
    "    \n",
    "    # Compute F1-score at different thresholds\n",
    "    f_25 = f1_score(label, target_25)\n",
    "    f_50 = f1_score(label, target_50)\n",
    "    f_75 = f1_score(label, target_75)\n",
    "    \n",
    "    # Display results\n",
    "    print(f'Thresholds: \\t {100*target_1:.2f}%\\t|{100*target_2:.2f}%\\t|{100*target_3:.2f}%')\n",
    "    print(40*'-')\n",
    "    print('Accuracy:\\t', round(acc_25 * 100, 2), '|', round(acc_50 * 100, 2), '|', round(acc_75 * 100, 2))\n",
    "    print('IoU:\\t\\t', round(iou_25 * 100, 2), '|', round(iou_50 * 100, 2), '|', round(iou_75 * 100, 2))\n",
    "    print('F-score:\\t', round(f_25 * 100, 2), '|', round(f_50 * 100, 2), '|', round(f_75 * 100, 2))\n",
    "\n",
    "# Compute and display the metrics\n",
    "compute_metrics(lbl, threshold_1, threshold_2, threshold_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_probability_distribution_zoom(pos_probs, neg_probs, zoom_ylim=(0, 2), threshold=.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's work on the pixels and understand FN and FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_img_count = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    data = next(iter(valid_loader))\n",
    "\n",
    "    inp, lab = data\n",
    "    \n",
    "    inp = inp.to(DEVICE)\n",
    "    lab = lab.to(DEVICE)\n",
    "    pred = model(inp) \n",
    "\n",
    "    i = 0\n",
    "    lab_unit = lab[i, 0, :, :].cpu().numpy()\n",
    "    inp_unit = inp[i].cpu().numpy()\n",
    "    inp_unit = np.transpose(inp_unit[:3], (1, 2, 0))\n",
    "\n",
    "    pred_img = pred[i, 0, :, :].cpu().numpy()\n",
    "    pred_img = np.where(pred_img > 0.5, 1, 0)  # Threshold to binary\n",
    "    \n",
    "    #print(pred_img.shape)\n",
    "    #print(pred_img[100,100])\n",
    "\n",
    "    #print(len(inp))\n",
    "\n",
    "    # Count positive and negative pixels in prediction and ground truth\n",
    "    pred_positive = np.sum(pred_img == 1)\n",
    "    pred_negative = np.sum(pred_img == 0)\n",
    "    lab_positive = np.sum(lab_unit == 1)\n",
    "    lab_negative = np.sum(lab_unit == 0)\n",
    "\n",
    "    # Print shapes and pixel counts\n",
    "    print(f\"Prediction Shape: {pred_img.shape}\")\n",
    "    print(f\"Prediction Positive Pixels (1): {pred_positive}\")\n",
    "    print(f\"Prediction Negative Pixels (0): {pred_negative}\")\n",
    "    print(f\"Ground Truth Positive Pixels (1): {lab_positive}\")\n",
    "    print(f\"Ground Truth Negative Pixels (0): {lab_negative}\")\n",
    "    #print(f\"Batch Size: {len(inp)}\")\n",
    "\n",
    "    # Calculate TP, TN, FP, FN\n",
    "    TP = np.sum((pred_img == 1) & (lab_unit == 1))  # True Positives\n",
    "    TN = np.sum((pred_img == 0) & (lab_unit == 0))  # True Negatives\n",
    "    FP = np.sum((pred_img == 1) & (lab_unit == 0))  # False Positives\n",
    "    FN = np.sum((pred_img == 0) & (lab_unit == 1))  # False Negatives\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity\n",
    "    specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\\n\")\n",
    "    \n",
    "    print(\"Metrics:\")\n",
    "    print(f\"Accuracy: \\t\\t{accuracy:.4f}\")\n",
    "    print(f\"Recall (Sensitivity): \\t{recall:.4f}\")\n",
    "    print(f\"Specificity: \\t\\t{specificity:.4f}\")\n",
    "    print(f\"Precision: \\t\\t{precision:.4f}\")\n",
    "    print(f\"F1-Score: \\t\\t{f1_score:.4f}\")\n",
    "    print(f\"IoU: \\t\\t\\t{iou:.4f}\")\n",
    "\n",
    "\n",
    "    # Plot images\n",
    "    NUM_ROWS = 1\n",
    "    IMGs_IN_ROW = 3\n",
    "    f, ax = plt.subplots(NUM_ROWS, IMGs_IN_ROW, figsize=(10, 10))\n",
    "\n",
    "    ax[0].imshow((inp_unit - inp_unit.min()) / (inp_unit.max() - inp_unit.min()))  # Normalize for display\n",
    "    ax[1].imshow(pred_img, cmap='binary_r')\n",
    "    ax[2].imshow(lab_unit, cmap='binary_r')\n",
    "\n",
    "    ax[0].set_title(f'Original Image | {actual_img_count + 1}')\n",
    "    ax[1].set_title(f'Prediction | {actual_img_count + 1}')\n",
    "    ax[2].set_title(f'Ground Truth | {actual_img_count + 1}')\n",
    "\n",
    "    # Remove tick labels for a cleaner plot\n",
    "    for a in ax:\n",
    "        a.set_yticklabels([])\n",
    "        a.set_xticklabels([])\n",
    "\n",
    "    #print(f'ID: {actual_img_count + 1} | IoU: {round(iou_score, 3)}')\n",
    "    \n",
    "    # Save selected images\n",
    "    #if actual_img_count in [15, 22, 29]:\n",
    "    #    plt.savefig(f'imgs/img{actual_img_count}.png', dpi=500, bbox_inches='tight', pad_inches=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dimensions of the images\n",
    "height, width = pred_img.shape\n",
    "\n",
    "# Get corner pixel values for prediction\n",
    "pred_upper_left = pred_img[0, 0]\n",
    "pred_upper_right = pred_img[0, width - 1]\n",
    "pred_bottom_left = pred_img[height - 1, 0]\n",
    "pred_bottom_right = pred_img[height - 1, width - 1]\n",
    "\n",
    "# Get corner pixel values for ground truth\n",
    "lab_upper_left = lab_unit[0, 0]\n",
    "lab_upper_right = lab_unit[0, width - 1]\n",
    "lab_bottom_left = lab_unit[height - 1, 0]\n",
    "lab_bottom_right = lab_unit[height - 1, width - 1]\n",
    "\n",
    "# Print corner pixel values\n",
    "print(\"Prediction Corner Pixels:\")\n",
    "print(f\"Upper Left: {pred_upper_left}, Upper Right: {pred_upper_right}\")\n",
    "print(f\"Bottom Left: {pred_bottom_left}, Bottom Right: {pred_bottom_right}\")\n",
    "\n",
    "print(\"\\nGround Truth Corner Pixels:\")\n",
    "print(f\"Upper Left: {lab_upper_left}, Upper Right: {lab_upper_right}\")\n",
    "print(f\"Bottom Left: {lab_bottom_left}, Bottom Right: {lab_bottom_right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_errors_on_predictions_by_set(loader):\n",
    "    with torch.no_grad():\n",
    "        model.eval()  # Set model to evaluation mode\n",
    "\n",
    "        log = []  # Overall log for all batches\n",
    "        total_non_blank_masks = 0\n",
    "        total_avg_iou = 0\n",
    "\n",
    "        # Loop through all batches in the DataLoader\n",
    "        for batch_idx, (inp, lab) in enumerate(loader):\n",
    "            inp = inp.to(DEVICE)\n",
    "            lab = lab.to(DEVICE)\n",
    "            pred = model(inp)\n",
    "\n",
    "            batch_size = inp.size(0)  # Number of images in the batch\n",
    "\n",
    "            # Loop through all images in the batch\n",
    "            for i in range(batch_size):\n",
    "                img_log = {}\n",
    "\n",
    "                lab_unit = lab[i, 0, :, :].cpu().numpy()  # Ground truth\n",
    "                inp_unit = inp[i].cpu().numpy()  # Input image\n",
    "                inp_unit = np.transpose(inp_unit[:3], (1, 2, 0))  # Adjust to HxWxC for RGB channels\n",
    "\n",
    "                pred_img = pred[i, 0, :, :].cpu().numpy()  # Prediction\n",
    "                pred_img = np.where(pred_img > 0.5, 1, 0)  # Threshold to binary\n",
    "\n",
    "                # Count TP, TN, FP, FN\n",
    "                TP = np.sum((pred_img == 1) & (lab_unit == 1))\n",
    "                TN = np.sum((pred_img == 0) & (lab_unit == 0))\n",
    "                FP = np.sum((pred_img == 1) & (lab_unit == 0))\n",
    "                FN = np.sum((pred_img == 0) & (lab_unit == 1))\n",
    "\n",
    "                # Initialize the log dictionary\n",
    "                img_log[\"TP\"] = TP\n",
    "                img_log[\"TN\"] = TN\n",
    "                img_log[\"FP\"] = FP\n",
    "                img_log[\"FN\"] = FN\n",
    "\n",
    "                img_log[\"pred_positive\"] = np.sum(pred_img == 1)\n",
    "                img_log[\"pred_negative\"] = np.sum(pred_img == 0)\n",
    "                img_log[\"lab_positive\"] = np.sum(lab_unit == 1)\n",
    "                img_log[\"lab_negative\"] = np.sum(lab_unit == 0)\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = (TP + TN) / (TP + TN + FP + FN) if (TP + TN + FP + FN) > 0 else 0\n",
    "                recall = TP / (TP + FN) if (TP + FN) > 0 else 0  # Sensitivity\n",
    "                specificity = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "                precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "                f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "                iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
    "\n",
    "                img_log[\"accuracy\"] = accuracy\n",
    "                img_log[\"recall\"] = recall\n",
    "                img_log[\"specificity\"] = specificity\n",
    "                img_log[\"precision\"] = precision\n",
    "                img_log[\"f1_score\"] = f1_score\n",
    "                img_log[\"iou\"] = iou\n",
    "\n",
    "                log.append(img_log)\n",
    "\n",
    "                # Print results for each image\n",
    "                print(f\"\\nBatch {batch_idx + 1}, Image {i + 1}/{batch_size}\")\n",
    "                print(\"Confusion Matrix:\")\n",
    "                print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "                print(\"Metrics:\")\n",
    "                print(f\"Accuracy: \\t\\t{accuracy:.4f}\")\n",
    "                print(f\"Recall (Sensitivity): \\t{recall:.4f}\")\n",
    "                print(f\"Specificity: \\t\\t{specificity:.4f}\")\n",
    "                print(f\"Precision: \\t\\t{precision:.4f}\")\n",
    "                print(f\"F1-Score: \\t\\t{f1_score:.4f}\")\n",
    "                print(f\"IoU: \\t\\t\\t{iou:.4f}\")\n",
    "\n",
    "                # Create an overlay with FP (yellow) and FN (green)\n",
    "                overlay = np.zeros((*pred_img.shape, 3), dtype=np.float32)  # Create a blank RGB image\n",
    "\n",
    "                # Assign colors for FP and FN\n",
    "                overlay[(pred_img == 1) & (lab_unit == 0)] = [1, 1, 0]  # Yellow for FP\n",
    "                overlay[(pred_img == 0) & (lab_unit == 1)] = [0, 1, 0]  # Green for FN\n",
    "\n",
    "                # Combine the overlay with a black-and-white version of the prediction\n",
    "                highlighted_pred = overlay  # Use the overlay directly for colored visualization\n",
    "\n",
    "                # Plot images for the current image in the batch\n",
    "                fig = plt.figure(figsize=(12, 15))  # Set overall figure size\n",
    "\n",
    "                # First row: Original image, Prediction, Ground Truth\n",
    "                ax1 = fig.add_subplot(2, 3, 1)\n",
    "                ax1.imshow((inp_unit - inp_unit.min()) / (inp_unit.max() - inp_unit.min()))  # Normalize for display\n",
    "                ax1.set_title(f'Original Image | {i + 1}')\n",
    "                ax1.axis('off')\n",
    "\n",
    "                ax2 = fig.add_subplot(2, 3, 2)\n",
    "                ax2.imshow(pred_img, cmap='binary_r')\n",
    "                ax2.set_title(f'Prediction | {i + 1}')\n",
    "                ax2.axis('off')\n",
    "\n",
    "                ax3 = fig.add_subplot(2, 3, 3)\n",
    "                ax3.imshow(lab_unit, cmap='binary_r')\n",
    "                ax3.set_title(f'Ground Truth | {i + 1}')\n",
    "                ax3.axis('off')\n",
    "\n",
    "                # Second row: Larger Prediction with FP and FN highlights\n",
    "                ax4 = fig.add_subplot(2, 1, 2)  # Spanning the entire width of the second row\n",
    "                ax4.imshow(highlighted_pred)\n",
    "                ax4.set_title(f'Prediction with FP (Yellow) & FN (Green) | {i + 1}')\n",
    "                ax4.axis('off')\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "                # Update IoU calculation for non-blank masks\n",
    "                if img_log[\"lab_positive\"] != 0:\n",
    "                    total_non_blank_masks += 1\n",
    "                    total_avg_iou += img_log[\"iou\"]\n",
    "\n",
    "        # Final summary\n",
    "        print('\\n\\nimage:\\tP+\\tP-\\tM+\\tM-\\tTP\\tTN\\tFP\\tFN\\tacc\\trec\\tspec\\tprec\\tf1_s\\tiou')\n",
    "        for j, img_log in enumerate(log):\n",
    "            print(\n",
    "                f\" {j+1} \\t{img_log['pred_positive']}\\t{img_log['pred_negative']}\\t{img_log['lab_positive']}\\t{img_log['lab_negative']}\"\n",
    "                f\"\\t{img_log['TP']}\\t{img_log['TN']}\\t{img_log['FP']}\\t{img_log['FN']}\\t{img_log['accuracy']:.3f} \"\n",
    "                f\"\\t{img_log['recall']:.3f}\\t{img_log['specificity']:.3f}\\t{img_log['precision']:.3f}\"\n",
    "                f\"\\t{img_log['f1_score']:.3f}\\t{img_log['iou']:.3f}\"\n",
    "            )\n",
    "\n",
    "        print(f'\\nNb of non-blank masks: {total_non_blank_masks}, avg_iou: {(total_avg_iou / total_non_blank_masks):.6f}')\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_errors_on_predictions_by_set(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_errors_on_predictions_by_set(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_errors_on_predictions_by_set(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm, pos_probs, neg_probs, nb_of_images_eval = compute_confusion_matrix_with_distributions(model, train_loader, DEVICE)\n",
    "display_confusion_matrix_with_metrics_and_distributions(cm, pos_probs, neg_probs, nb_of_images_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "5b-Model-KNL",
   "language": "python",
   "name": "5b-model-knl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
